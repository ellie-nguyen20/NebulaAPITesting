<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 03-Sep-2025 at 17:57:54 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">12 tests took 00:04:22.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">2 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">10 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.9.6&#34;, &#34;Platform&#34;: &#34;macOS-15.5-arm64-arm-64bit&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.4.1&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;html&#34;: &#34;4.1.1&#34;, &#34;asyncio&#34;: &#34;1.1.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;allure-pytest&#34;: &#34;2.13.2&#34;}}, &#34;tests&#34;: {&#34;tests/serverless_models/text_models/test_deepseek_r1_0528.py::test_deepseek_r1_0528_free_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_deepseek_r1_0528.py::test_deepseek_r1_0528_free_simple&#34;, &#34;duration&#34;: &#34;00:00:32&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_deepseek_r1_0528.py::test_deepseek_r1_0528_free_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:32&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;---------------------------- Captured stderr setup -----------------------------\nINFO:conftest:\u2705 Loaded configuration from config.yaml\nINFO:conftest:[pytest] Using user from CLI: Member7 -&amp;gt; thivunguyen1506+member7@gmail.com\nINFO:conftest:Login once for entire test session with user: thivunguyen1506+member7@gmail.com\nINFO:conftest:\u2705 Login successful - token will be reused for all tests\nINFO:conftest:Found 1 API keys for user\nINFO:conftest:Found 1 personal API keys\nINFO:conftest:Found personal API key: Unnamed (ID: 348)\nINFO:conftest:\u2705 Using API key from logged-in user\n\n------------------------------ Captured log setup ------------------------------\nINFO     conftest:conftest.py:50 \u2705 Loaded configuration from config.yaml\nINFO     conftest:conftest.py:108 [pytest] Using user from CLI: Member7 -&amp;gt; thivunguyen1506+member7@gmail.com\nINFO     conftest:conftest.py:133 Login once for entire test session with user: thivunguyen1506+member7@gmail.com\nINFO     conftest:conftest.py:141 \u2705 Login successful - token will be reused for all tests\nINFO     conftest:conftest.py:194 Found 1 API keys for user\nINFO     conftest:conftest.py:238 Found 1 personal API keys\nINFO     conftest:conftest.py:203 Found personal API key: Unnamed (ID: 348)\nINFO     conftest:conftest.py:92 \u2705 Using API key from logged-in user\n\n----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_deepseek_r1_0528:\ud83d\ude80 Starting DeepSeek R1-0528 (Free) text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_deepseek_r1_0528:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling deepseek-r1-0528-free with text prompt\nINFO:serverless_models.text_models.test_deepseek_r1_0528:\ud83d\udcdd DeepSeek R1-0528 (Free) text response: Yes, **Montreal is unequivocally a thriving global hub for AI**, renowned for its exceptional research, talent density, industry investment, and collaborative ecosystem. Here&amp;#x27;s why:\n\n### 1. **World-Leading Research Powerhouse**\n   - **MILA (Montreal Institute for Learning Algorithms)**: Founded by Turing Award winner **Yoshua Bengio**, MILA is the world\u2019s largest academic research center in deep learning, attracting top scientists globally.\n   - **Academic Excellence**: Universities like **McGill**, **Universit\u00e9 de Montr\u00e9al**, and **Polytechnique Montr\u00e9al** rank among the top for AI research, producing cutting-edge work in reinforcement learning, NLP, and computer vision.\n   - **Government Support**: Quebec and Canada have invested heavily (e.g., **Pan-Canadian AI Strategy**, **SCALE AI consortium**) to cement Montreal\u2019s leadership.\n\n### 2. **Major Corporate &amp;amp; Startup Presence**\n   - **Tech Giants**: Google DeepMind, Microsoft Research, Meta (FAIR Lab), Samsung AI, NVIDIA, IBM, and Thales all have significant AI labs in Montreal.\n   - **Homegrown Success**: Companies like **Element AI** (acquired by ServiceNow), **Lobe.ai** (Microsoft), **Hopper** (AI travel), and **Lumina Chat** thrive here.\n   - **Startup Ecosystem**: Over 200 AI startups leverage Montreal\u2019s talent, supported by incubators like **District 3**, **Notman House**, and **Mila\u2019s startup studio**.\n\n### 3. **Unmatched Talent Pool**\n   - Montreal produces **8,000+ AI-related graduates annually** from local universities.\n   - **Global Magnet**: Ranked \\#1 in North America for AI talent concentration (per capita) and attracts researchers from 80+ countries due to its academic prestige and quality of life.\n\n### 4. **Strategic Advantages**\n   - **Cost Efficiency**: Lower operating costs vs. hubs like SF or NYC.\n   - **Bilingual Talent**: French-English fluency eases global collaboration, especially with European markets.\n   - **Quality of Life**: Vibrant culture, affordability, and inclusivity help retain talent.\n\n### 5. **Funding &amp;amp; Growth Momentum**\n   - AI startups in Quebec raised **$1.3B in 2021 alone**, reflecting investor confidence.\n   - Initiatives like **SCALE AI** ($230M supply chain AI fund) and federal tax credits accelerate commercialization.\n\n### Challenges &amp;amp; Opportunities\n   - **Commercialization**: Scaling research into market-ready products remains a focus.\n   - **Global Competition**: Rivalry with Toronto, the EU, and the US demands continuous innovation.\n   - **Inclusion**: Efforts to diversify AI talent (e.g., women in STEM) are ongoing.\n\n### Verdict\nMontreal isn\u2019t just &amp;quot;a hub&amp;quot;\u2014it\u2019s a **global epicenter for AI research and innovation**, driven by unparalleled academic leadership, corporate investment, and a dynamic policy environment. For talent, startups, or enterprises in AI, it\u2019s a top-tier destination. \ud83c\udf1f\ud83c\udde8\ud83c\udde6\nINFO:serverless_models.text_models.test_deepseek_r1_0528:\u2705 DeepSeek R1-0528 (Free) text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_deepseek_r1_0528:test_deepseek_r1_0528.py:9 \ud83d\ude80 Starting DeepSeek R1-0528 (Free) text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_deepseek_r1_0528:test_deepseek_r1_0528.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling deepseek-r1-0528-free with text prompt\nINFO     serverless_models.text_models.test_deepseek_r1_0528:test_deepseek_r1_0528.py:32 \ud83d\udcdd DeepSeek R1-0528 (Free) text response: Yes, **Montreal is unequivocally a thriving global hub for AI**, renowned for its exceptional research, talent density, industry investment, and collaborative ecosystem. Here&amp;#x27;s why:\n\n### 1. **World-Leading Research Powerhouse**\n   - **MILA (Montreal Institute for Learning Algorithms)**: Founded by Turing Award winner **Yoshua Bengio**, MILA is the world\u2019s largest academic research center in deep learning, attracting top scientists globally.\n   - **Academic Excellence**: Universities like **McGill**, **Universit\u00e9 de Montr\u00e9al**, and **Polytechnique Montr\u00e9al** rank among the top for AI research, producing cutting-edge work in reinforcement learning, NLP, and computer vision.\n   - **Government Support**: Quebec and Canada have invested heavily (e.g., **Pan-Canadian AI Strategy**, **SCALE AI consortium**) to cement Montreal\u2019s leadership.\n\n### 2. **Major Corporate &amp;amp; Startup Presence**\n   - **Tech Giants**: Google DeepMind, Microsoft Research, Meta (FAIR Lab), Samsung AI, NVIDIA, IBM, and Thales all have significant AI labs in Montreal.\n   - **Homegrown Success**: Companies like **Element AI** (acquired by ServiceNow), **Lobe.ai** (Microsoft), **Hopper** (AI travel), and **Lumina Chat** thrive here.\n   - **Startup Ecosystem**: Over 200 AI startups leverage Montreal\u2019s talent, supported by incubators like **District 3**, **Notman House**, and **Mila\u2019s startup studio**.\n\n### 3. **Unmatched Talent Pool**\n   - Montreal produces **8,000+ AI-related graduates annually** from local universities.\n   - **Global Magnet**: Ranked \\#1 in North America for AI talent concentration (per capita) and attracts researchers from 80+ countries due to its academic prestige and quality of life.\n\n### 4. **Strategic Advantages**\n   - **Cost Efficiency**: Lower operating costs vs. hubs like SF or NYC.\n   - **Bilingual Talent**: French-English fluency eases global collaboration, especially with European markets.\n   - **Quality of Life**: Vibrant culture, affordability, and inclusivity help retain talent.\n\n### 5. **Funding &amp;amp; Growth Momentum**\n   - AI startups in Quebec raised **$1.3B in 2021 alone**, reflecting investor confidence.\n   - Initiatives like **SCALE AI** ($230M supply chain AI fund) and federal tax credits accelerate commercialization.\n\n### Challenges &amp;amp; Opportunities\n   - **Commercialization**: Scaling research into market-ready products remains a focus.\n   - **Global Competition**: Rivalry with Toronto, the EU, and the US demands continuous innovation.\n   - **Inclusion**: Efforts to diversify AI talent (e.g., women in STEM) are ongoing.\n\n### Verdict\nMontreal isn\u2019t just &amp;quot;a hub&amp;quot;\u2014it\u2019s a **global epicenter for AI research and innovation**, driven by unparalleled academic leadership, corporate investment, and a dynamic policy environment. For talent, startups, or enterprises in AI, it\u2019s a top-tier destination. \ud83c\udf1f\ud83c\udde8\ud83c\udde6\nINFO     serverless_models.text_models.test_deepseek_r1_0528:test_deepseek_r1_0528.py:37 \u2705 DeepSeek R1-0528 (Free) text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_deepseek_r1_0528_paid.py::test_deepseek_r1_0528_paid_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_deepseek_r1_0528_paid.py::test_deepseek_r1_0528_paid_simple&#34;, &#34;duration&#34;: &#34;00:00:40&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_deepseek_r1_0528_paid.py::test_deepseek_r1_0528_paid_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:40&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_deepseek_r1_0528_paid:\ud83d\ude80 Starting DeepSeek R1-0528 (Paid) text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_deepseek_r1_0528_paid:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling deepseek-r1-0528-paid with text prompt\nINFO:serverless_models.text_models.test_deepseek_r1_0528_paid:\ud83d\udcdd DeepSeek R1-0528 (Paid) text response: Yes, **Montreal is undeniably a thriving and globally significant hub for the AI industry**, consistently ranked among the top AI ecosystems worldwide (often alongside cities like Toronto, London, NYC, SF, and Beijing).\n\nHere&amp;#x27;s why Montreal excels in AI:\n\n1.  **World-Leading Research Powerhouse (MILA):**\n    *   Home to **MILA (Montreal Institute for Learning Algorithms)**, founded by Turing Award winner **Yoshua Bengio**. MILA is arguably the world&amp;#x27;s largest academic research center focused on deep learning and reinforcement learning.\n    *   Attracts top global talent (researchers, PhD students, postdocs).\n    *   Pioneering fundamental research with significant impact.\n\n2.  **Strong Academic Foundation:**\n    *   Close ties and deep collaborations with **Universit\u00e9 de Montr\u00e9al** and **McGill University**, both renowned for their AI/CS programs.\n    *   Produces a steady stream of highly skilled graduates.\n\n3.  **Significant Industry Presence &amp;amp; Investment:**\n    *   Major tech giants have established **AI research labs** in Montreal: **Google Brain, Microsoft Research, Meta AI (FAIR), Samsung AI Center, DeepMind (Alphabet), IBM Research, NVIDIA**, etc.\n    *   Thriving **startup ecosystem**: Companies like **Element AI** (acquired by ServiceNow), **Hopper**, **Imagia**, **Milvus**, **GHGSat**, and many others focusing on AI applications across various sectors (health, finance, gaming, climate).\n    *   Venture capital actively invests in Montreal AI startups.\n\n4.  **Strong Government Support &amp;amp; Strategy:**\n    *   **Federal &amp;amp; Provincial Backing:** Significant investment through the **Pan-Canadian Artificial Intelligence Strategy**, **Scale AI** (a supercluster focused on AI supply chains), **Investissement Qu\u00e9bec**, and various provincial tax credits &amp;amp; grants supporting R&amp;amp;D and commercialization.\n    *   Proactive policies aimed at attracting talent and investment.\n\n5.  **Deep Talent Pool:**\n    *   A concentration of world-class researchers, engineers, and entrepreneurs specializing in machine learning, deep learning, NLP, computer vision, robotics, and more.\n    *   Graduates from local universities are highly sought after globally.\n\n6.  **Supportive Ecosystem &amp;amp; Culture:**\n    *   Vibrant AI community with regular meetups, conferences (e.g., events hosted by MILA), and collaborative initiatives.\n    *   A culture of innovation and collaboration between academia, industry, and government.\n\n**Challenges &amp;amp; Considerations:**\n\n*   **Competition:** Facing intense global competition for top talent (especially from the US) and investment.\n*   **Commercialization:** While research is stellar, translating research breakthroughs into large-scale commercial success stories *within Montreal* remains an ongoing effort compared to some other hubs.\n*   **Cost &amp;amp; Brain Drain:** While often more affordable than SF or NYC, rising costs and the lure of higher US salaries can be a factor. The federal government offers specific programs to attract top international AI talent.\n*   **Language:** While the tech/AI sector is very bilingual (French/English), French is the primary language in Quebec. This can be an asset or a consideration depending on perspective.\n\n**Conclusion:**\n\nMontreal is not just a hub; it&amp;#x27;s a **global epicenter for AI research and innovation**, particularly in deep learning. Its combination of **world-leading academic research (MILA), strong university ties, significant industry labs, government support, and a growing startup ecosystem** creates a powerful and dynamic environment. While challenges like global competition exist, Montreal&amp;#x27;s established foundation, ongoing investments, and collaborative spirit solidify its position as a **thriving and critically important hub** in the global AI landscape. If you&amp;#x27;re interested in AI research or joining an innovative AI company, Montreal is undoubtedly a top destination.\nINFO:serverless_models.text_models.test_deepseek_r1_0528_paid:\u2705 DeepSeek R1-0528 (Paid) text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_deepseek_r1_0528_paid:test_deepseek_r1_0528_paid.py:9 \ud83d\ude80 Starting DeepSeek R1-0528 (Paid) text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_deepseek_r1_0528_paid:test_deepseek_r1_0528_paid.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling deepseek-r1-0528-paid with text prompt\nINFO     serverless_models.text_models.test_deepseek_r1_0528_paid:test_deepseek_r1_0528_paid.py:32 \ud83d\udcdd DeepSeek R1-0528 (Paid) text response: Yes, **Montreal is undeniably a thriving and globally significant hub for the AI industry**, consistently ranked among the top AI ecosystems worldwide (often alongside cities like Toronto, London, NYC, SF, and Beijing).\n\nHere&amp;#x27;s why Montreal excels in AI:\n\n1.  **World-Leading Research Powerhouse (MILA):**\n    *   Home to **MILA (Montreal Institute for Learning Algorithms)**, founded by Turing Award winner **Yoshua Bengio**. MILA is arguably the world&amp;#x27;s largest academic research center focused on deep learning and reinforcement learning.\n    *   Attracts top global talent (researchers, PhD students, postdocs).\n    *   Pioneering fundamental research with significant impact.\n\n2.  **Strong Academic Foundation:**\n    *   Close ties and deep collaborations with **Universit\u00e9 de Montr\u00e9al** and **McGill University**, both renowned for their AI/CS programs.\n    *   Produces a steady stream of highly skilled graduates.\n\n3.  **Significant Industry Presence &amp;amp; Investment:**\n    *   Major tech giants have established **AI research labs** in Montreal: **Google Brain, Microsoft Research, Meta AI (FAIR), Samsung AI Center, DeepMind (Alphabet), IBM Research, NVIDIA**, etc.\n    *   Thriving **startup ecosystem**: Companies like **Element AI** (acquired by ServiceNow), **Hopper**, **Imagia**, **Milvus**, **GHGSat**, and many others focusing on AI applications across various sectors (health, finance, gaming, climate).\n    *   Venture capital actively invests in Montreal AI startups.\n\n4.  **Strong Government Support &amp;amp; Strategy:**\n    *   **Federal &amp;amp; Provincial Backing:** Significant investment through the **Pan-Canadian Artificial Intelligence Strategy**, **Scale AI** (a supercluster focused on AI supply chains), **Investissement Qu\u00e9bec**, and various provincial tax credits &amp;amp; grants supporting R&amp;amp;D and commercialization.\n    *   Proactive policies aimed at attracting talent and investment.\n\n5.  **Deep Talent Pool:**\n    *   A concentration of world-class researchers, engineers, and entrepreneurs specializing in machine learning, deep learning, NLP, computer vision, robotics, and more.\n    *   Graduates from local universities are highly sought after globally.\n\n6.  **Supportive Ecosystem &amp;amp; Culture:**\n    *   Vibrant AI community with regular meetups, conferences (e.g., events hosted by MILA), and collaborative initiatives.\n    *   A culture of innovation and collaboration between academia, industry, and government.\n\n**Challenges &amp;amp; Considerations:**\n\n*   **Competition:** Facing intense global competition for top talent (especially from the US) and investment.\n*   **Commercialization:** While research is stellar, translating research breakthroughs into large-scale commercial success stories *within Montreal* remains an ongoing effort compared to some other hubs.\n*   **Cost &amp;amp; Brain Drain:** While often more affordable than SF or NYC, rising costs and the lure of higher US salaries can be a factor. The federal government offers specific programs to attract top international AI talent.\n*   **Language:** While the tech/AI sector is very bilingual (French/English), French is the primary language in Quebec. This can be an asset or a consideration depending on perspective.\n\n**Conclusion:**\n\nMontreal is not just a hub; it&amp;#x27;s a **global epicenter for AI research and innovation**, particularly in deep learning. Its combination of **world-leading academic research (MILA), strong university ties, significant industry labs, government support, and a growing startup ecosystem** creates a powerful and dynamic environment. While challenges like global competition exist, Montreal&amp;#x27;s established foundation, ongoing investments, and collaborative spirit solidify its position as a **thriving and critically important hub** in the global AI landscape. If you&amp;#x27;re interested in AI research or joining an innovative AI company, Montreal is undoubtedly a top destination.\nINFO     serverless_models.text_models.test_deepseek_r1_0528_paid:test_deepseek_r1_0528_paid.py:37 \u2705 DeepSeek R1-0528 (Paid) text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_deepseek_r1_free.py::test_deepseek_r1_free_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_deepseek_r1_free.py::test_deepseek_r1_free_simple&#34;, &#34;duration&#34;: &#34;00:00:39&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_deepseek_r1_free.py::test_deepseek_r1_free_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:39&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_deepseek_r1_free:\ud83d\ude80 Starting DeepSeek R1-Free text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_deepseek_r1_free:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling deepseek-r1-free with text prompt\nINFO:serverless_models.text_models.test_deepseek_r1_free:\ud83d\udcdd DeepSeek R1-Free text response: \n\nYes, Montreal is widely recognized as a thriving hub for the AI industry, driven by several key factors:\n\n1. **Academic Excellence**: \n   - The city is home to prestigious institutions like McGill University and Universit\u00e9 de Montr\u00e9al, which are leaders in AI research. \n   - The **Montreal Institute for Learning Algorithms (MILA)**, led by Turing Award winner Yoshua Bengio, is a global epicenter for deep learning research, attracting top talent and fostering innovation.\n\n2. **Industry Presence**:\n   - Major tech companies, including Google (DeepMind), Microsoft, Meta, Samsung, and IBM, have established AI research labs in Montreal, leveraging local expertise.\n   - Startups like **Element AI** (acquired by ServiceNow in 2021) and newer ventures such as **Imagia** and **Keatext** highlight a dynamic startup ecosystem.\n\n3. **Government and Funding Support**:\n   - Canada\u2019s **Pan-Canadian AI Strategy** prioritizes Montreal, alongside Toronto and Edmonton, investing in research and talent development.\n   - Quebec offers tax incentives and grants for tech innovation, further bolstering the sector.\n\n4. **Collaborative Ecosystem**:\n   - Strong academia-industry partnerships (e.g., MILA\u2019s collaborations with Google Brain) accelerate innovation and commercialization.\n   - Venture capital firms like **Real Ventures** and **Inovia Capital** actively invest in Montreal-based AI startups.\n\n5. **Talent Pipeline**:\n   - Montreal\u2019s universities produce a steady stream of AI graduates, while initiatives like the **IVADO** consortium facilitate interdisciplinary research and industry connections.\n\n6. **Community and Events**:\n   - The city hosts major AI conferences (e.g., NeurIPS workshops) and local meetups, fostering knowledge-sharing and networking.\n\n**Challenges**:\n   - Competition from other hubs (e.g., Toronto\u2019s Vector Institute) and brain drain to the U.S. remain concerns.\n   - Language barriers (French predominance) and higher provincial taxes could pose minor hurdles for some international talent or firms.\n\n**Conclusion**: Montreal\u2019s blend of cutting-edge research, corporate investment, government backing, and a vibrant startup culture solidifies its status as a global AI leader. While challenges exist, its strengths in academia, industry collaboration, and innovation make it a cornerstone of the AI ecosystem.\nINFO:serverless_models.text_models.test_deepseek_r1_free:\u2705 DeepSeek R1-Free text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_deepseek_r1_free:test_deepseek_r1_free.py:9 \ud83d\ude80 Starting DeepSeek R1-Free text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_deepseek_r1_free:test_deepseek_r1_free.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling deepseek-r1-free with text prompt\nINFO     serverless_models.text_models.test_deepseek_r1_free:test_deepseek_r1_free.py:32 \ud83d\udcdd DeepSeek R1-Free text response: \n\nYes, Montreal is widely recognized as a thriving hub for the AI industry, driven by several key factors:\n\n1. **Academic Excellence**: \n   - The city is home to prestigious institutions like McGill University and Universit\u00e9 de Montr\u00e9al, which are leaders in AI research. \n   - The **Montreal Institute for Learning Algorithms (MILA)**, led by Turing Award winner Yoshua Bengio, is a global epicenter for deep learning research, attracting top talent and fostering innovation.\n\n2. **Industry Presence**:\n   - Major tech companies, including Google (DeepMind), Microsoft, Meta, Samsung, and IBM, have established AI research labs in Montreal, leveraging local expertise.\n   - Startups like **Element AI** (acquired by ServiceNow in 2021) and newer ventures such as **Imagia** and **Keatext** highlight a dynamic startup ecosystem.\n\n3. **Government and Funding Support**:\n   - Canada\u2019s **Pan-Canadian AI Strategy** prioritizes Montreal, alongside Toronto and Edmonton, investing in research and talent development.\n   - Quebec offers tax incentives and grants for tech innovation, further bolstering the sector.\n\n4. **Collaborative Ecosystem**:\n   - Strong academia-industry partnerships (e.g., MILA\u2019s collaborations with Google Brain) accelerate innovation and commercialization.\n   - Venture capital firms like **Real Ventures** and **Inovia Capital** actively invest in Montreal-based AI startups.\n\n5. **Talent Pipeline**:\n   - Montreal\u2019s universities produce a steady stream of AI graduates, while initiatives like the **IVADO** consortium facilitate interdisciplinary research and industry connections.\n\n6. **Community and Events**:\n   - The city hosts major AI conferences (e.g., NeurIPS workshops) and local meetups, fostering knowledge-sharing and networking.\n\n**Challenges**:\n   - Competition from other hubs (e.g., Toronto\u2019s Vector Institute) and brain drain to the U.S. remain concerns.\n   - Language barriers (French predominance) and higher provincial taxes could pose minor hurdles for some international talent or firms.\n\n**Conclusion**: Montreal\u2019s blend of cutting-edge research, corporate investment, government backing, and a vibrant startup culture solidifies its status as a global AI leader. While challenges exist, its strengths in academia, industry collaboration, and innovation make it a cornerstone of the AI ecosystem.\nINFO     serverless_models.text_models.test_deepseek_r1_free:test_deepseek_r1_free.py:37 \u2705 DeepSeek R1-Free text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_deepseek_v3_0324.py::test_deepseek_v3_0324_free_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_deepseek_v3_0324.py::test_deepseek_v3_0324_free_simple&#34;, &#34;duration&#34;: &#34;00:00:40&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_deepseek_v3_0324.py::test_deepseek_v3_0324_free_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:40&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_deepseek_v3_0324:\ud83d\ude80 Starting DeepSeek V3-0324 (Free) text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_deepseek_v3_0324:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling deepseek-v3-0324-free with text prompt\nINFO:serverless_models.text_models.test_deepseek_v3_0324:\ud83d\udcdd DeepSeek V3-0324 (Free) text response: Yes, Montreal has established itself as a **thriving hub for the AI industry**, recognized globally for its leadership in artificial intelligence research, innovation, and commercialization. Here\u2019s why:\n\n### **1. World-Class Research &amp;amp; Academia**\n- **Mila (Montreal Institute for Learning Algorithms)**, led by **Yoshua Bengio** (a Turing Award winner and AI pioneer), is one of the world\u2019s top AI research labs, specializing in **deep learning and reinforcement learning**.\n- Strong ties with **McGill University**, **Universit\u00e9 de Montr\u00e9al**, and **HEC Montr\u00e9al**, which produce top-tier AI talent.\n- Significant contributions to **natural language processing (NLP)**, **computer vision**, and **robotics**.\n\n### **2. Government &amp;amp; Private Sector Investment**\n- **Canada\u2019s Pan-Canadian AI Strategy** has heavily invested in Montreal\u2019s AI ecosystem.\n- **Scale AI** (a Montreal-based AI supercluster) supports AI adoption in supply chains, manufacturing, and logistics with over **$300 million in funding**.\n- Major tech companies have set up AI labs in Montreal, including **Google Brain, Microsoft Research, Meta (FAIR), Samsung AI, and DeepMind**.\n\n### **3. Startup Ecosystem &amp;amp; Industry Adoption**\n- Montreal has a booming **AI startup scene**, with companies like **Element AI (acquired by ServiceNow), Coveo, Hopper, and LightSpeed** leading the charge.\n- AI is applied across industries, including **healthcare (e.g., Dialogue), gaming (e.g., Unity), finance, and autonomous systems**.\n\n### **4. AI Policy &amp;amp; Ethics Leadership**\n- Montreal is home to the **Responsible AI initiative**, focusing on ethical AI development and policy.\n- The **Montreal Declaration for Responsible AI** promotes human rights and inclusivity in AI.\n\n### **5. Global Recognition &amp;amp; Talent Attraction**\n- Montreal ranks among the **top AI cities worldwide** (alongside Toronto, San Francisco, and London).\n- The city attracts **international researchers, engineers, and entrepreneurs** due to its collaborative ecosystem and high quality of life.\n\n### **Challenges?**\n- Competition with other hubs (e.g., Toronto, Waterloo, and the U.S.).\n- Retaining talent amid higher salaries offered by U.S. tech giants.\n\n### **Verdict: Yes, Montreal is a major AI hub.**\nIts combination of **cutting-edge research, strong industry partnerships, government backing, and a vibrant startup scene** makes it a key player in the global AI landscape.  \n\nWould you like insights on specific AI companies, job opportunities, or events in Montreal?\nINFO:serverless_models.text_models.test_deepseek_v3_0324:\u2705 DeepSeek V3-0324 (Free) text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_deepseek_v3_0324:test_deepseek_v3_0324.py:9 \ud83d\ude80 Starting DeepSeek V3-0324 (Free) text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_deepseek_v3_0324:test_deepseek_v3_0324.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling deepseek-v3-0324-free with text prompt\nINFO     serverless_models.text_models.test_deepseek_v3_0324:test_deepseek_v3_0324.py:32 \ud83d\udcdd DeepSeek V3-0324 (Free) text response: Yes, Montreal has established itself as a **thriving hub for the AI industry**, recognized globally for its leadership in artificial intelligence research, innovation, and commercialization. Here\u2019s why:\n\n### **1. World-Class Research &amp;amp; Academia**\n- **Mila (Montreal Institute for Learning Algorithms)**, led by **Yoshua Bengio** (a Turing Award winner and AI pioneer), is one of the world\u2019s top AI research labs, specializing in **deep learning and reinforcement learning**.\n- Strong ties with **McGill University**, **Universit\u00e9 de Montr\u00e9al**, and **HEC Montr\u00e9al**, which produce top-tier AI talent.\n- Significant contributions to **natural language processing (NLP)**, **computer vision**, and **robotics**.\n\n### **2. Government &amp;amp; Private Sector Investment**\n- **Canada\u2019s Pan-Canadian AI Strategy** has heavily invested in Montreal\u2019s AI ecosystem.\n- **Scale AI** (a Montreal-based AI supercluster) supports AI adoption in supply chains, manufacturing, and logistics with over **$300 million in funding**.\n- Major tech companies have set up AI labs in Montreal, including **Google Brain, Microsoft Research, Meta (FAIR), Samsung AI, and DeepMind**.\n\n### **3. Startup Ecosystem &amp;amp; Industry Adoption**\n- Montreal has a booming **AI startup scene**, with companies like **Element AI (acquired by ServiceNow), Coveo, Hopper, and LightSpeed** leading the charge.\n- AI is applied across industries, including **healthcare (e.g., Dialogue), gaming (e.g., Unity), finance, and autonomous systems**.\n\n### **4. AI Policy &amp;amp; Ethics Leadership**\n- Montreal is home to the **Responsible AI initiative**, focusing on ethical AI development and policy.\n- The **Montreal Declaration for Responsible AI** promotes human rights and inclusivity in AI.\n\n### **5. Global Recognition &amp;amp; Talent Attraction**\n- Montreal ranks among the **top AI cities worldwide** (alongside Toronto, San Francisco, and London).\n- The city attracts **international researchers, engineers, and entrepreneurs** due to its collaborative ecosystem and high quality of life.\n\n### **Challenges?**\n- Competition with other hubs (e.g., Toronto, Waterloo, and the U.S.).\n- Retaining talent amid higher salaries offered by U.S. tech giants.\n\n### **Verdict: Yes, Montreal is a major AI hub.**\nIts combination of **cutting-edge research, strong industry partnerships, government backing, and a vibrant startup scene** makes it a key player in the global AI landscape.  \n\nWould you like insights on specific AI companies, job opportunities, or events in Montreal?\nINFO     serverless_models.text_models.test_deepseek_v3_0324:test_deepseek_v3_0324.py:37 \u2705 DeepSeek V3-0324 (Free) text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_deepseek_v3_0324_paid.py::test_deepseek_v3_0324_paid_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_deepseek_v3_0324_paid.py::test_deepseek_v3_0324_paid_simple&#34;, &#34;duration&#34;: &#34;00:00:12&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_deepseek_v3_0324_paid.py::test_deepseek_v3_0324_paid_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:12&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_deepseek_v3_0324_paid:\ud83d\ude80 Starting DeepSeek V3-0324 (Paid) text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_deepseek_v3_0324_paid:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling deepseek-v3-0324-paid with text prompt\nINFO:serverless_models.text_models.test_deepseek_v3_0324_paid:\ud83d\udcdd DeepSeek V3-0324 (Paid) text response: Yes, Montreal has established itself as a thriving hub for the artificial intelligence (AI) industry, renowned for its world-leading research, vibrant startup ecosystem, and strong government support. Here\u2019s why:\n\n### **1. Leading AI Research Institutions**\n- **Mila (Montreal Institute for Learning Algorithms)**: Founded by Yoshua Bengio (a Turing Award winner), Mila is one of the world\u2019s top AI research labs, specializing in deep learning and machine learning. It collaborates closely with universities like **McGill** and **Universit\u00e9 de Montr\u00e9al**.\n- **IVADO**: A consortium for AI research, bringing together academia, industry, and government to advance AI in fields like healthcare, transportation, and finance.\n\n### **2. Strong Academic Ecosystem**\n- Montreal boasts top-ranked universities with AI-focused programs:\n  - **Universit\u00e9 de Montr\u00e9al** (ranked among the best for AI research)\n  - **McGill University** (a global leader in computer science)\n  - **HEC Montr\u00e9al** (for AI in business and analytics)\n\n### **3. Thriving Startup &amp;amp; Corporate AI Scene**\n- Montreal is home to **hundreds of AI startups**, including:\n  - **Element AI** (acquired by ServiceNow) \u2013 a major success story.\n  - **Hopper** (AI-powered travel app, now a unicorn).\n  - **DeepMind** (Google\u2019s AI lab) has a significant presence.\n  - **Meta (Facebook), Microsoft, Samsung, and Thales** also have AI labs in the city.\n\n### **4. Government &amp;amp; Investment Support**\n- The **Qu\u00e9bec government** and **Canadian federal funding** have heavily invested in AI, offering tax incentives and grants.\n- **Scale AI** (a Montr\u00e9al-based supercluster) funds AI projects in supply chain and logistics.\n\n### **5. AI Talent Pool**\n- Montreal attracts top global talent due to its **specialized visa programs for tech workers** and a high quality of life.\n- The city has one of the **highest concentrations of AI PhDs** in the world.\n\n### **6. Global Recognition**\n- Montreal consistently ranks among the **top AI cities worldwide**, competing with hubs like San Francisco, London, and Beijing.\n- It hosts major AI conferences like **ICLR (International Conference on Learning Representations)**.\n\n### **Challenges**\n- Competition with other hubs (e.g., Toronto, Waterloo, and U.S. tech hubs).\n- Retaining startups as they scale (some get acquired by larger foreign firms).\n\n### **Conclusion**\nMontreal is undeniably a **global AI powerhouse**, driven by cutting-edge research, a dynamic startup culture, and strong collaboration between academia and industry. If you&amp;#x27;re in AI, Montreal is a prime location for innovation and growth.  \n\nWould you like insights on job opportunities or specific AI sectors in Montreal?\nINFO:serverless_models.text_models.test_deepseek_v3_0324_paid:\u2705 DeepSeek V3-0324 (Paid) text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_deepseek_v3_0324_paid:test_deepseek_v3_0324_paid.py:9 \ud83d\ude80 Starting DeepSeek V3-0324 (Paid) text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_deepseek_v3_0324_paid:test_deepseek_v3_0324_paid.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling deepseek-v3-0324-paid with text prompt\nINFO     serverless_models.text_models.test_deepseek_v3_0324_paid:test_deepseek_v3_0324_paid.py:32 \ud83d\udcdd DeepSeek V3-0324 (Paid) text response: Yes, Montreal has established itself as a thriving hub for the artificial intelligence (AI) industry, renowned for its world-leading research, vibrant startup ecosystem, and strong government support. Here\u2019s why:\n\n### **1. Leading AI Research Institutions**\n- **Mila (Montreal Institute for Learning Algorithms)**: Founded by Yoshua Bengio (a Turing Award winner), Mila is one of the world\u2019s top AI research labs, specializing in deep learning and machine learning. It collaborates closely with universities like **McGill** and **Universit\u00e9 de Montr\u00e9al**.\n- **IVADO**: A consortium for AI research, bringing together academia, industry, and government to advance AI in fields like healthcare, transportation, and finance.\n\n### **2. Strong Academic Ecosystem**\n- Montreal boasts top-ranked universities with AI-focused programs:\n  - **Universit\u00e9 de Montr\u00e9al** (ranked among the best for AI research)\n  - **McGill University** (a global leader in computer science)\n  - **HEC Montr\u00e9al** (for AI in business and analytics)\n\n### **3. Thriving Startup &amp;amp; Corporate AI Scene**\n- Montreal is home to **hundreds of AI startups**, including:\n  - **Element AI** (acquired by ServiceNow) \u2013 a major success story.\n  - **Hopper** (AI-powered travel app, now a unicorn).\n  - **DeepMind** (Google\u2019s AI lab) has a significant presence.\n  - **Meta (Facebook), Microsoft, Samsung, and Thales** also have AI labs in the city.\n\n### **4. Government &amp;amp; Investment Support**\n- The **Qu\u00e9bec government** and **Canadian federal funding** have heavily invested in AI, offering tax incentives and grants.\n- **Scale AI** (a Montr\u00e9al-based supercluster) funds AI projects in supply chain and logistics.\n\n### **5. AI Talent Pool**\n- Montreal attracts top global talent due to its **specialized visa programs for tech workers** and a high quality of life.\n- The city has one of the **highest concentrations of AI PhDs** in the world.\n\n### **6. Global Recognition**\n- Montreal consistently ranks among the **top AI cities worldwide**, competing with hubs like San Francisco, London, and Beijing.\n- It hosts major AI conferences like **ICLR (International Conference on Learning Representations)**.\n\n### **Challenges**\n- Competition with other hubs (e.g., Toronto, Waterloo, and U.S. tech hubs).\n- Retaining startups as they scale (some get acquired by larger foreign firms).\n\n### **Conclusion**\nMontreal is undeniably a **global AI powerhouse**, driven by cutting-edge research, a dynamic startup culture, and strong collaboration between academia and industry. If you&amp;#x27;re in AI, Montreal is a prime location for innovation and growth.  \n\nWould you like insights on job opportunities or specific AI sectors in Montreal?\nINFO     serverless_models.text_models.test_deepseek_v3_0324_paid:test_deepseek_v3_0324_paid.py:37 \u2705 DeepSeek V3-0324 (Paid) text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_l3_3_ms_nevoria_70b.py::test_l3_3_ms_nevoria_70b_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_l3_3_ms_nevoria_70b.py::test_l3_3_ms_nevoria_70b_simple&#34;, &#34;duration&#34;: &#34;00:00:24&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_l3_3_ms_nevoria_70b.py::test_l3_3_ms_nevoria_70b_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:24&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_l3_3_ms_nevoria_70b:\ud83d\ude80 Starting L3.3-MS-Nevoria-70b text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_l3_3_ms_nevoria_70b:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling l3.3-ms-nevoria-70b with text prompt\nINFO:serverless_models.text_models.test_l3_3_ms_nevoria_70b:\ud83d\udcdd L3.3-MS-Nevoria-70b text response: Yes, Montreal is a thriving hub for the artificial intelligence (AI) industry. Here are some reasons why:\n\n1. Research institutions: Montreal is home to some of the world&amp;#x27;s top research institutions in AI, such as the Montreal Institute for Learning Algorithms (MILA), which was co-founded by Dr. Yoshua Bengio, one of the pioneers in the field of deep learning. Other notable institutions include the University of Montreal, McGill University, and the Polytechnique Montreal.\n\n2. Innovation ecosystem: The city has a vibrant innovation ecosystem that fosters collaboration between academia, industry, and government. Organizations like Centech, a technology transfer organization, and the Quartier de l&amp;#x27;innovation, a neighborhood dedicated to innovation and entrepreneurship, provide resources and support for AI startups and researchers.\n\n3. Talent pool: Montreal has a large pool of highly skilled AI researchers and engineers, thanks to its strong universities and research institutions. This talent pool attracts tech companies and startups looking to develop and apply AI technologies.\n\n4. Funding and support: The Canadian government, the province of Quebec, and the City of Montreal provide funding and support for AI research and innovation through various programs and initiatives. This includes tax credits, grants, and investments in AI-focused funds.\n\n5. Industry presence: Many major tech companies, including Google, Microsoft, Facebook, and IBM, have AI research labs or development centers in Montreal. These companies often partner with local researchers and startups to advance AI research and applications.\n\n6. Networking events: Montreal hosts various AI-related conferences, workshops, and meetups throughout the year, providing opportunities for researchers, entrepreneurs, and industry professionals to connect, share ideas, and collaborate on new projects.\n\nSome of the areas where Montreal is particularly strong in AI include:\n\n- Deep learning\n- Natural language processing\n- Computer vision\n- Reinforcement learning\n- Explainable AI\n- AI ethics\n\nOverall, Montreal&amp;#x27;s unique combination of world-class research institutions, a thriving innovation ecosystem, a talented workforce, and government support make it an attractive location for AI companies, researchers, and entrepreneurs.\nINFO:serverless_models.text_models.test_l3_3_ms_nevoria_70b:\u2705 L3.3-MS-Nevoria-70b text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_l3_3_ms_nevoria_70b:test_l3_3_ms_nevoria_70b.py:9 \ud83d\ude80 Starting L3.3-MS-Nevoria-70b text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_l3_3_ms_nevoria_70b:test_l3_3_ms_nevoria_70b.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling l3.3-ms-nevoria-70b with text prompt\nINFO     serverless_models.text_models.test_l3_3_ms_nevoria_70b:test_l3_3_ms_nevoria_70b.py:32 \ud83d\udcdd L3.3-MS-Nevoria-70b text response: Yes, Montreal is a thriving hub for the artificial intelligence (AI) industry. Here are some reasons why:\n\n1. Research institutions: Montreal is home to some of the world&amp;#x27;s top research institutions in AI, such as the Montreal Institute for Learning Algorithms (MILA), which was co-founded by Dr. Yoshua Bengio, one of the pioneers in the field of deep learning. Other notable institutions include the University of Montreal, McGill University, and the Polytechnique Montreal.\n\n2. Innovation ecosystem: The city has a vibrant innovation ecosystem that fosters collaboration between academia, industry, and government. Organizations like Centech, a technology transfer organization, and the Quartier de l&amp;#x27;innovation, a neighborhood dedicated to innovation and entrepreneurship, provide resources and support for AI startups and researchers.\n\n3. Talent pool: Montreal has a large pool of highly skilled AI researchers and engineers, thanks to its strong universities and research institutions. This talent pool attracts tech companies and startups looking to develop and apply AI technologies.\n\n4. Funding and support: The Canadian government, the province of Quebec, and the City of Montreal provide funding and support for AI research and innovation through various programs and initiatives. This includes tax credits, grants, and investments in AI-focused funds.\n\n5. Industry presence: Many major tech companies, including Google, Microsoft, Facebook, and IBM, have AI research labs or development centers in Montreal. These companies often partner with local researchers and startups to advance AI research and applications.\n\n6. Networking events: Montreal hosts various AI-related conferences, workshops, and meetups throughout the year, providing opportunities for researchers, entrepreneurs, and industry professionals to connect, share ideas, and collaborate on new projects.\n\nSome of the areas where Montreal is particularly strong in AI include:\n\n- Deep learning\n- Natural language processing\n- Computer vision\n- Reinforcement learning\n- Explainable AI\n- AI ethics\n\nOverall, Montreal&amp;#x27;s unique combination of world-class research institutions, a thriving innovation ecosystem, a talented workforce, and government support make it an attractive location for AI companies, researchers, and entrepreneurs.\nINFO     serverless_models.text_models.test_l3_3_ms_nevoria_70b:test_l3_3_ms_nevoria_70b.py:37 \u2705 L3.3-MS-Nevoria-70b text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_l3_70b_euryale.py::test_l3_70b_euryale_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_l3_70b_euryale.py::test_l3_70b_euryale_simple&#34;, &#34;duration&#34;: &#34;00:00:24&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_l3_70b_euryale.py::test_l3_70b_euryale_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:24&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_l3_70b_euryale:\ud83d\ude80 Starting L3-70B-Euryale text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_l3_70b_euryale:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling l3-70b-euryale with text prompt\nINFO:serverless_models.text_models.test_l3_70b_euryale:\ud83d\udcdd L3-70B-Euryale text response: Yes, Montreal has emerged as a major hub for artificial intelligence (AI) research and development in recent years. Several factors have contributed to this:\n\n1. Research institutions: Montreal is home to world-renowned research institutions like the University of Montreal, McGill University, and the Mila artificial intelligence lab, which have strong AI research programs. Mila is one of the largest deep learning research groups in the world.\n\n2. Government support: The Canadian government has provided significant funding for AI research and development through initiatives like the Pan-Canadian AI Strategy and the Canada First Research Excellence Fund. This funding has helped support AI research and talent development in Montreal.\n\n3. Industry presence: Many major tech companies, including Google, Microsoft, Facebook, Samsung, and Baidu, have established AI research labs or offices in Montreal. They tap into the city&amp;#x27;s talent pool of researchers and engineers. \n\n4. Startup ecosystem: Montreal has a thriving startup ecosystem with many AI-focused startups. Organizations like Element AI, founded by AI pioneer Yoshua Bengio, are driving innovation in areas like AI for healthcare and environmental sustainability.\n\n5. Brain drain reversal: Historically, many Canadian AI researchers moved to the US for better opportunities. However, the growing AI ecosystem in Montreal is now attracting researchers and entrepreneurs back to Canada.\n\n6. Cost of living: Compared to other major AI hubs like San Francisco or New York, Montreal has a lower cost of living, making it an attractive option for startups and researchers.\n\n7. Language: Montreal is a bilingual city, making it a bridge between French-speaking and English-speaking AI communities. This has facilitated collaborations and attracted international talent.\n\nWhile other Canadian cities like Toronto and Vancouver also have significant AI activity, Montreal&amp;#x27;s unique combination of research institutions, government support, industry presence, and ecosystem has made it stand out as a major AI hub. The city&amp;#x27;s AI sector continues to grow, with new research initiatives, startups, and industry investments emerging regularly.\nINFO:serverless_models.text_models.test_l3_70b_euryale:\u2705 L3-70B-Euryale text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_l3_70b_euryale:test_l3_70b_euryale.py:9 \ud83d\ude80 Starting L3-70B-Euryale text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_l3_70b_euryale:test_l3_70b_euryale.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling l3-70b-euryale with text prompt\nINFO     serverless_models.text_models.test_l3_70b_euryale:test_l3_70b_euryale.py:32 \ud83d\udcdd L3-70B-Euryale text response: Yes, Montreal has emerged as a major hub for artificial intelligence (AI) research and development in recent years. Several factors have contributed to this:\n\n1. Research institutions: Montreal is home to world-renowned research institutions like the University of Montreal, McGill University, and the Mila artificial intelligence lab, which have strong AI research programs. Mila is one of the largest deep learning research groups in the world.\n\n2. Government support: The Canadian government has provided significant funding for AI research and development through initiatives like the Pan-Canadian AI Strategy and the Canada First Research Excellence Fund. This funding has helped support AI research and talent development in Montreal.\n\n3. Industry presence: Many major tech companies, including Google, Microsoft, Facebook, Samsung, and Baidu, have established AI research labs or offices in Montreal. They tap into the city&amp;#x27;s talent pool of researchers and engineers. \n\n4. Startup ecosystem: Montreal has a thriving startup ecosystem with many AI-focused startups. Organizations like Element AI, founded by AI pioneer Yoshua Bengio, are driving innovation in areas like AI for healthcare and environmental sustainability.\n\n5. Brain drain reversal: Historically, many Canadian AI researchers moved to the US for better opportunities. However, the growing AI ecosystem in Montreal is now attracting researchers and entrepreneurs back to Canada.\n\n6. Cost of living: Compared to other major AI hubs like San Francisco or New York, Montreal has a lower cost of living, making it an attractive option for startups and researchers.\n\n7. Language: Montreal is a bilingual city, making it a bridge between French-speaking and English-speaking AI communities. This has facilitated collaborations and attracted international talent.\n\nWhile other Canadian cities like Toronto and Vancouver also have significant AI activity, Montreal&amp;#x27;s unique combination of research institutions, government support, industry presence, and ecosystem has made it stand out as a major AI hub. The city&amp;#x27;s AI sector continues to grow, with new research initiatives, startups, and industry investments emerging regularly.\nINFO     serverless_models.text_models.test_l3_70b_euryale:test_l3_70b_euryale.py:37 \u2705 L3-70B-Euryale text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_l3_8b_stheno.py::test_l3_8b_stheno_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_l3_8b_stheno.py::test_l3_8b_stheno_simple&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_l3_8b_stheno.py::test_l3_8b_stheno_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_l3_8b_stheno:\ud83d\ude80 Starting L3-8B-Stheno text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_l3_8b_stheno:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling l3-8b-stheno with text prompt\nINFO:serverless_models.text_models.test_l3_8b_stheno:\ud83d\udcdd L3-8B-Stheno text response: Montreal has indeed emerged as a significant hub for the artificial intelligence (AI) industry in recent years. Several factors contribute to its thriving AI ecosystem:\n\n1. Language and talent: Montreal&amp;#x27;s predominantly French-speaking population and the presence of top universities (e.g., McGill and Universit\u00e9 de Montr\u00e9al) provide access to a pool of skilled professionals in AI, machine learning, and related fields.\n\n2. Government support: The Quebec government has implemented various initiatives to foster the growth of the AI sector, including tax incentives, funding for research and development, and programs to attract international talent.\n\n3. Concentration of AI companies: Montreal is home to numerous AI startups, scale-ups, and established players, such as H2O.ai, Element AI, MDA, and Aider. These companies drive innovation and collaboration within the community.\n\n4. Research institutions: World-renowned institutions like the Montreal Institute for Learning Algorithms (MILA) and the Montreal Neuroscience Centre (MCN) conduct cutting-edge AI and related research, further enhancing the city&amp;#x27;s reputation.\n\n5. Strong connections to Silicon Valley and Europe: Montreal&amp;#x27;s proximity to major tech hubs and the presence of flight connections enable easy collaboration, partnerships, and talent acquisition from around the world.\n\n6. Growing funding: Montreal-based AI startups have attracted significant venture capital investment in recent years, demonstrating investor confidence in the region&amp;#x27;s potential.\n\nWhile other cities, like Toronto and Vancouver, also have substantial AI presence, Montreal&amp;#x27;s unique blend of language, talent, government support, and company concentration has made it a notable AI hub. Its reputation continues to grow as a preferred location for AI innovation and development.\nINFO:serverless_models.text_models.test_l3_8b_stheno:\u2705 L3-8B-Stheno text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_l3_8b_stheno:test_l3_8b_stheno.py:9 \ud83d\ude80 Starting L3-8B-Stheno text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_l3_8b_stheno:test_l3_8b_stheno.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling l3-8b-stheno with text prompt\nINFO     serverless_models.text_models.test_l3_8b_stheno:test_l3_8b_stheno.py:32 \ud83d\udcdd L3-8B-Stheno text response: Montreal has indeed emerged as a significant hub for the artificial intelligence (AI) industry in recent years. Several factors contribute to its thriving AI ecosystem:\n\n1. Language and talent: Montreal&amp;#x27;s predominantly French-speaking population and the presence of top universities (e.g., McGill and Universit\u00e9 de Montr\u00e9al) provide access to a pool of skilled professionals in AI, machine learning, and related fields.\n\n2. Government support: The Quebec government has implemented various initiatives to foster the growth of the AI sector, including tax incentives, funding for research and development, and programs to attract international talent.\n\n3. Concentration of AI companies: Montreal is home to numerous AI startups, scale-ups, and established players, such as H2O.ai, Element AI, MDA, and Aider. These companies drive innovation and collaboration within the community.\n\n4. Research institutions: World-renowned institutions like the Montreal Institute for Learning Algorithms (MILA) and the Montreal Neuroscience Centre (MCN) conduct cutting-edge AI and related research, further enhancing the city&amp;#x27;s reputation.\n\n5. Strong connections to Silicon Valley and Europe: Montreal&amp;#x27;s proximity to major tech hubs and the presence of flight connections enable easy collaboration, partnerships, and talent acquisition from around the world.\n\n6. Growing funding: Montreal-based AI startups have attracted significant venture capital investment in recent years, demonstrating investor confidence in the region&amp;#x27;s potential.\n\nWhile other cities, like Toronto and Vancouver, also have substantial AI presence, Montreal&amp;#x27;s unique blend of language, talent, government support, and company concentration has made it a notable AI hub. Its reputation continues to grow as a preferred location for AI innovation and development.\nINFO     serverless_models.text_models.test_l3_8b_stheno:test_l3_8b_stheno.py:37 \u2705 L3-8B-Stheno text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_llama_3_3_70b.py::test_llama_3_3_70b_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_llama_3_3_70b.py::test_llama_3_3_70b_simple&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_llama_3_3_70b.py::test_llama_3_3_70b_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;config_with_api_key = {&amp;#x27;api_key&amp;#x27;: &amp;#x27;sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;base_url&amp;#x27;: &amp;#x27;https://dev-portal-api.nebulablock.com/api/v1&amp;#x27;, &amp;#x27;chat_completion...roxy.nebulablock.com/v1/chat/completions&amp;#x27;, &amp;#x27;embedding_url&amp;#x27;: &amp;#x27;https://dev-llm-proxy.nebulablock.com/v1/embeddings&amp;#x27;, ...}\n\n    def test_llama_3_3_70b_simple(config_with_api_key):\n        logger.info(&amp;quot;\ud83d\ude80 Starting Llama 3.3-70B text test with simple prompt&amp;quot;)\n    \n        try:\n            text_api = TextModelsAPI(config_with_api_key)\n            logger.info(&amp;quot;\u2705 TextModelsAPI instance created successfully&amp;quot;)\n    \n&amp;gt;           response = text_api.call_model(\n                model_name=&amp;quot;llama-3.3-70b&amp;quot;,\n                prompt=&amp;quot;Is Montreal a thriving hub for the AI industry?&amp;quot;,\n                system_message=&amp;quot;You are a helpful assistant.&amp;quot;\n            )\n\ntests/serverless_models/text_models/test_llama_3_3_70b.py:15: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;api_clients.text_models.TextModelsAPI object at 0x1024523a0&amp;gt;\nmodel_name = &amp;#x27;llama-3.3-70b&amp;#x27;\nprompt = &amp;#x27;Is Montreal a thriving hub for the AI industry?&amp;#x27;\nsystem_message = &amp;#x27;You are a helpful assistant.&amp;#x27;, kwargs = {}\nmodel_config = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;model&amp;#x27;: &amp;#x27;meta-llama/Llama-3.3-70B-Instruct&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, &amp;#x27;temperature&amp;#x27;: 1, ...}\nmessages = [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Is Montreal a thriving hub for the AI industry?&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}]\npayload = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;messages&amp;#x27;: [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Is Montr...riving hub for the AI industry?&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;meta-llama/Llama-3.3-70B-Instruct&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, ...}\nheaders = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\nresponse = &amp;lt;Response [403]&amp;gt;\n\n    def call_model(\n        self,\n        model_name: str,\n        prompt: str,\n        system_message: Optional[str] = None,\n        **kwargs\n    ) -&amp;gt; Dict[str, Any]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Call text model with text prompt only.\n    \n        Args:\n            model_name: Model identifier (e.g., &amp;#x27;gpt-4o-mini&amp;#x27;, &amp;#x27;claude-sonnet-4&amp;#x27;)\n            prompt: Text prompt\n            system_message: Optional system message\n            **kwargs: Override default model parameters\n    \n        Returns:\n            API response dictionary\n        &amp;quot;&amp;quot;&amp;quot;\n        # Get model configuration\n        model_config = self._get_model_config(model_name)\n        if not model_config:\n            raise ValueError(f&amp;quot;Unknown model: {model_name}&amp;quot;)\n    \n        # Build messages\n        messages = []\n        if system_message:\n            messages.append({&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: system_message})\n    \n        # Add user message (text-only)\n        messages.append({&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt})\n        self.logger.info(f&amp;quot;Calling {model_name} with text prompt&amp;quot;)\n    \n        # Merge default config with overrides\n        payload = {**model_config, &amp;quot;messages&amp;quot;: messages, **kwargs}\n    \n        # Make direct request since we have full URL\n        headers = {\n            &amp;quot;Authorization&amp;quot;: f&amp;quot;Bearer {self.api_key}&amp;quot;,\n            &amp;quot;Content-Type&amp;quot;: &amp;quot;application/json&amp;quot;\n        }\n    \n        self.logger.debug(f&amp;quot;Making request to: {self.base_model_url}&amp;quot;)\n        self.logger.debug(f&amp;quot;Headers: {headers}&amp;quot;)\n        self.logger.debug(f&amp;quot;Payload: {payload}&amp;quot;)\n    \n        response = requests.post(self.base_model_url, headers=headers, json=payload)\n    \n        # Log response for debugging\n        self.logger.debug(f&amp;quot;Response status: {response.status_code}&amp;quot;)\n        self.logger.debug(f&amp;quot;Response headers: {dict(response.headers)}&amp;quot;)\n    \n        if response.status_code != 200:\n            self.logger.error(f&amp;quot;Request failed with status {response.status_code}: {response.text}&amp;quot;)\n&amp;gt;           raise Exception(f&amp;quot;API request failed: {response.status_code} - {response.text}&amp;quot;)\nE           Exception: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=meta-llama/Llama-3.3-70B-Instruct\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\napi_clients/text_models.py:174: Exception\n\n----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_llama_3_3_70b:\ud83d\ude80 Starting Llama 3.3-70B text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_llama_3_3_70b:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling llama-3.3-70b with text prompt\nERROR:api_clients.text_models:Request failed with status 403: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=meta-llama/Llama-3.3-70B-Instruct\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\nERROR:serverless_models.text_models.test_llama_3_3_70b:\u274c Llama 3.3-70B text test failed: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=meta-llama/Llama-3.3-70B-Instruct\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_llama_3_3_70b:test_llama_3_3_70b.py:9 \ud83d\ude80 Starting Llama 3.3-70B text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_llama_3_3_70b:test_llama_3_3_70b.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling llama-3.3-70b with text prompt\nERROR    api_clients.text_models:text_models.py:173 Request failed with status 403: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=meta-llama/Llama-3.3-70B-Instruct\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\nERROR    serverless_models.text_models.test_llama_3_3_70b:test_llama_3_3_70b.py:40 \u274c Llama 3.3-70B text test failed: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=meta-llama/Llama-3.3-70B-Instruct\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\n&#34;}], &#34;tests/serverless_models/text_models/test_midnight_rose_70b.py::test_midnight_rose_70b_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_midnight_rose_70b.py::test_midnight_rose_70b_simple&#34;, &#34;duration&#34;: &#34;00:00:29&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_midnight_rose_70b.py::test_midnight_rose_70b_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:29&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_midnight_rose_70b:\ud83d\ude80 Starting Midnight Rose 70B text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_midnight_rose_70b:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling midnight-rose-70b with text prompt\nINFO:serverless_models.text_models.test_midnight_rose_70b:\ud83d\udcdd Midnight Rose 70B text response:  Yes, Montreal has emerged as a thriving hub for the AI industry, particularly in the field of deep learning and neural networks. This growth can be attributed to several factors:\n\n1. Strong academic institutions: Montreal is home to prestigious universities like the University of Montreal and McGill University, which are known for their world-class AI research programs. These institutions have produced many influential AI researchers and have attracted significant funding for their work.\n\n2. Talent pool: The city&amp;#x27;s vibrant academic environment has created a large pool of skilled AI professionals. Many graduates choose to stay in Montreal, contributing to the growth of the local AI industry.\n\n3. Presence of AI pioneers: Montreal has been able to attract some of the biggest names in AI, such as Yoshua Bengio, a pioneer in deep learning and a co-founder of Element AI, a leading AI startup in the city.\n\n4. Supportive government policies: The Canadian government has shown a strong commitment to supporting AI research and development. In 2017, it launched the Pan-Canadian Artificial Intelligence Strategy, which aims to increase investment in AI, develop talent, and support collaboration between industry, academia, and government.\n\n5. Growing startup ecosystem: Montreal is home to a growing number of AI startups, such as Element AI, C2RO, and Aifred Health. These companies are attracting significant investment and creating jobs in the city.\n\n6. Corporate investment: Major tech companies like Google, Facebook, and Microsoft have established AI research centers in Montreal, further strengthening the city&amp;#x27;s AI ecosystem.\n\n7. Collaborative environment: Montreal&amp;#x27;s AI community is known for its collaborative nature, with researchers, startups, and established companies working together on various projects and initiatives.\n\nIn summary, Montreal has all the ingredients to be a thriving hub for the AI industry: strong academic institutions, a large talent pool, supportive government policies, a growing startup ecosystem, corporate investment, and a collaborative environment. These factors have contributed to the city&amp;#x27;s emergence as a significant player in the global AI landscape.\nINFO:serverless_models.text_models.test_midnight_rose_70b:\u2705 Midnight Rose 70B text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_midnight_rose_70b:test_midnight_rose_70b.py:9 \ud83d\ude80 Starting Midnight Rose 70B text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_midnight_rose_70b:test_midnight_rose_70b.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling midnight-rose-70b with text prompt\nINFO     serverless_models.text_models.test_midnight_rose_70b:test_midnight_rose_70b.py:32 \ud83d\udcdd Midnight Rose 70B text response:  Yes, Montreal has emerged as a thriving hub for the AI industry, particularly in the field of deep learning and neural networks. This growth can be attributed to several factors:\n\n1. Strong academic institutions: Montreal is home to prestigious universities like the University of Montreal and McGill University, which are known for their world-class AI research programs. These institutions have produced many influential AI researchers and have attracted significant funding for their work.\n\n2. Talent pool: The city&amp;#x27;s vibrant academic environment has created a large pool of skilled AI professionals. Many graduates choose to stay in Montreal, contributing to the growth of the local AI industry.\n\n3. Presence of AI pioneers: Montreal has been able to attract some of the biggest names in AI, such as Yoshua Bengio, a pioneer in deep learning and a co-founder of Element AI, a leading AI startup in the city.\n\n4. Supportive government policies: The Canadian government has shown a strong commitment to supporting AI research and development. In 2017, it launched the Pan-Canadian Artificial Intelligence Strategy, which aims to increase investment in AI, develop talent, and support collaboration between industry, academia, and government.\n\n5. Growing startup ecosystem: Montreal is home to a growing number of AI startups, such as Element AI, C2RO, and Aifred Health. These companies are attracting significant investment and creating jobs in the city.\n\n6. Corporate investment: Major tech companies like Google, Facebook, and Microsoft have established AI research centers in Montreal, further strengthening the city&amp;#x27;s AI ecosystem.\n\n7. Collaborative environment: Montreal&amp;#x27;s AI community is known for its collaborative nature, with researchers, startups, and established companies working together on various projects and initiatives.\n\nIn summary, Montreal has all the ingredients to be a thriving hub for the AI industry: strong academic institutions, a large talent pool, supportive government policies, a growing startup ecosystem, corporate investment, and a collaborative environment. These factors have contributed to the city&amp;#x27;s emergence as a significant player in the global AI landscape.\nINFO     serverless_models.text_models.test_midnight_rose_70b:test_midnight_rose_70b.py:37 \u2705 Midnight Rose 70B text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_mistral_small_3_2_24b.py::test_mistral_small_3_2_24b_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_mistral_small_3_2_24b.py::test_mistral_small_3_2_24b_simple&#34;, &#34;duration&#34;: &#34;00:00:11&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_mistral_small_3_2_24b.py::test_mistral_small_3_2_24b_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:11&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_mistral_small_3_2_24b:\ud83d\ude80 Starting Mistral Small 3.2-24B text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_mistral_small_3_2_24b:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling mistral-small-3.2-24b with text prompt\nINFO:serverless_models.text_models.test_mistral_small_3_2_24b:\ud83d\udcdd Mistral Small 3.2-24B text response: Yes, Montreal has indeed become a thriving hub for the artificial intelligence (AI) industry in recent years. Here are a few reasons why:\n\n1. **Academic Excellence**: Montreal is home to world-renowned universities like the University of Montreal and McGill University, which have leading AI research labs and programs. The University of Montreal&amp;#x27;s Mila Institute, founded by Yoshua Bengio, one of the pioneers of deep learning, is one of the largest deep learning research institutes in the world.\n\n2. **Talent Pool**: The city&amp;#x27;s universities produce a steady stream of AI talent. According to the Montreal International AI Forum, Montreal has the highest concentration of AI startups in Canada and the third highest in the world, after San Francisco and Tel Aviv.\n\n3. **Government Support**: The Canadian and Quebec provincial governments have invested significantly in AI research and development. For instance, in 2017, the Canadian government announced a C$125 million investment in a pan-Canadian AI strategy, with a significant portion allocated to Montreal.\n\n4. **Presence of Major Tech Companies**: Several major tech companies, including Google, Microsoft, and Facebook, have established AI research labs in Montreal to take advantage of the city&amp;#x27;s AI talent and expertise.\n\n5. **Vibrant Startup Ecosystem**: Montreal has a growing number of AI startups, and it&amp;#x27;s home to AI-focused incubators and accelerators, such as District 3 and FounderFuel.\n\n6. **Diverse and Multilingual Workforce**: Montreal&amp;#x27;s diverse and multilingual workforce is an asset for tech companies looking to expand globally.\n\nHowever, like any other city, Montreal also faces challenges such as competition for AI talent and the need for continued investment in AI infrastructure. But overall, it&amp;#x27;s considered one of the top global hubs for AI.\n\nSources:\n- Montreal International AI Forum\n- Mila Institute\n- Government of Canada\n- Montreal International (general information about the city)\nINFO:serverless_models.text_models.test_mistral_small_3_2_24b:\u2705 Mistral Small 3.2-24B text test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_mistral_small_3_2_24b:test_mistral_small_3_2_24b.py:9 \ud83d\ude80 Starting Mistral Small 3.2-24B text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_mistral_small_3_2_24b:test_mistral_small_3_2_24b.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling mistral-small-3.2-24b with text prompt\nINFO     serverless_models.text_models.test_mistral_small_3_2_24b:test_mistral_small_3_2_24b.py:32 \ud83d\udcdd Mistral Small 3.2-24B text response: Yes, Montreal has indeed become a thriving hub for the artificial intelligence (AI) industry in recent years. Here are a few reasons why:\n\n1. **Academic Excellence**: Montreal is home to world-renowned universities like the University of Montreal and McGill University, which have leading AI research labs and programs. The University of Montreal&amp;#x27;s Mila Institute, founded by Yoshua Bengio, one of the pioneers of deep learning, is one of the largest deep learning research institutes in the world.\n\n2. **Talent Pool**: The city&amp;#x27;s universities produce a steady stream of AI talent. According to the Montreal International AI Forum, Montreal has the highest concentration of AI startups in Canada and the third highest in the world, after San Francisco and Tel Aviv.\n\n3. **Government Support**: The Canadian and Quebec provincial governments have invested significantly in AI research and development. For instance, in 2017, the Canadian government announced a C$125 million investment in a pan-Canadian AI strategy, with a significant portion allocated to Montreal.\n\n4. **Presence of Major Tech Companies**: Several major tech companies, including Google, Microsoft, and Facebook, have established AI research labs in Montreal to take advantage of the city&amp;#x27;s AI talent and expertise.\n\n5. **Vibrant Startup Ecosystem**: Montreal has a growing number of AI startups, and it&amp;#x27;s home to AI-focused incubators and accelerators, such as District 3 and FounderFuel.\n\n6. **Diverse and Multilingual Workforce**: Montreal&amp;#x27;s diverse and multilingual workforce is an asset for tech companies looking to expand globally.\n\nHowever, like any other city, Montreal also faces challenges such as competition for AI talent and the need for continued investment in AI infrastructure. But overall, it&amp;#x27;s considered one of the top global hubs for AI.\n\nSources:\n- Montreal International AI Forum\n- Mila Institute\n- Government of Canada\n- Montreal International (general information about the city)\nINFO     serverless_models.text_models.test_mistral_small_3_2_24b:test_mistral_small_3_2_24b.py:37 \u2705 Mistral Small 3.2-24B text test completed successfully\n\n&#34;}], &#34;tests/serverless_models/text_models/test_qwq_32b.py::test_qwq_32b_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/text_models/test_qwq_32b.py::test_qwq_32b_simple&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/text_models/test_qwq_32b.py::test_qwq_32b_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;config_with_api_key = {&amp;#x27;api_key&amp;#x27;: &amp;#x27;sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;base_url&amp;#x27;: &amp;#x27;https://dev-portal-api.nebulablock.com/api/v1&amp;#x27;, &amp;#x27;chat_completion...roxy.nebulablock.com/v1/chat/completions&amp;#x27;, &amp;#x27;embedding_url&amp;#x27;: &amp;#x27;https://dev-llm-proxy.nebulablock.com/v1/embeddings&amp;#x27;, ...}\n\n    def test_qwq_32b_simple(config_with_api_key):\n        logger.info(&amp;quot;\ud83d\ude80 Starting QwQ-32B text test with simple prompt&amp;quot;)\n    \n        try:\n            text_api = TextModelsAPI(config_with_api_key)\n            logger.info(&amp;quot;\u2705 TextModelsAPI instance created successfully&amp;quot;)\n    \n&amp;gt;           response = text_api.call_model(\n                model_name=&amp;quot;qwq-32b&amp;quot;,\n                prompt=&amp;quot;Is Montreal a thriving hub for the AI industry?&amp;quot;,\n                system_message=&amp;quot;You are a helpful assistant.&amp;quot;\n            )\n\ntests/serverless_models/text_models/test_qwq_32b.py:15: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;api_clients.text_models.TextModelsAPI object at 0x10246ae80&amp;gt;\nmodel_name = &amp;#x27;qwq-32b&amp;#x27;\nprompt = &amp;#x27;Is Montreal a thriving hub for the AI industry?&amp;#x27;\nsystem_message = &amp;#x27;You are a helpful assistant.&amp;#x27;, kwargs = {}\nmodel_config = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;model&amp;#x27;: &amp;#x27;Qwen/QwQ-32B&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, &amp;#x27;temperature&amp;#x27;: 1, ...}\nmessages = [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Is Montreal a thriving hub for the AI industry?&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}]\npayload = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;messages&amp;#x27;: [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Is Montreal a thriving hub for the AI industry?&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;Qwen/QwQ-32B&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, ...}\nheaders = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\nresponse = &amp;lt;Response [403]&amp;gt;\n\n    def call_model(\n        self,\n        model_name: str,\n        prompt: str,\n        system_message: Optional[str] = None,\n        **kwargs\n    ) -&amp;gt; Dict[str, Any]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Call text model with text prompt only.\n    \n        Args:\n            model_name: Model identifier (e.g., &amp;#x27;gpt-4o-mini&amp;#x27;, &amp;#x27;claude-sonnet-4&amp;#x27;)\n            prompt: Text prompt\n            system_message: Optional system message\n            **kwargs: Override default model parameters\n    \n        Returns:\n            API response dictionary\n        &amp;quot;&amp;quot;&amp;quot;\n        # Get model configuration\n        model_config = self._get_model_config(model_name)\n        if not model_config:\n            raise ValueError(f&amp;quot;Unknown model: {model_name}&amp;quot;)\n    \n        # Build messages\n        messages = []\n        if system_message:\n            messages.append({&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: system_message})\n    \n        # Add user message (text-only)\n        messages.append({&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt})\n        self.logger.info(f&amp;quot;Calling {model_name} with text prompt&amp;quot;)\n    \n        # Merge default config with overrides\n        payload = {**model_config, &amp;quot;messages&amp;quot;: messages, **kwargs}\n    \n        # Make direct request since we have full URL\n        headers = {\n            &amp;quot;Authorization&amp;quot;: f&amp;quot;Bearer {self.api_key}&amp;quot;,\n            &amp;quot;Content-Type&amp;quot;: &amp;quot;application/json&amp;quot;\n        }\n    \n        self.logger.debug(f&amp;quot;Making request to: {self.base_model_url}&amp;quot;)\n        self.logger.debug(f&amp;quot;Headers: {headers}&amp;quot;)\n        self.logger.debug(f&amp;quot;Payload: {payload}&amp;quot;)\n    \n        response = requests.post(self.base_model_url, headers=headers, json=payload)\n    \n        # Log response for debugging\n        self.logger.debug(f&amp;quot;Response status: {response.status_code}&amp;quot;)\n        self.logger.debug(f&amp;quot;Response headers: {dict(response.headers)}&amp;quot;)\n    \n        if response.status_code != 200:\n            self.logger.error(f&amp;quot;Request failed with status {response.status_code}: {response.text}&amp;quot;)\n&amp;gt;           raise Exception(f&amp;quot;API request failed: {response.status_code} - {response.text}&amp;quot;)\nE           Exception: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=Qwen/QwQ-32B\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\napi_clients/text_models.py:174: Exception\n\n----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.text_models.test_qwq_32b:\ud83d\ude80 Starting QwQ-32B text test with simple prompt\nINFO:api_clients.text_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.text_models.test_qwq_32b:\u2705 TextModelsAPI instance created successfully\nINFO:api_clients.text_models:Calling qwq-32b with text prompt\nERROR:api_clients.text_models:Request failed with status 403: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=Qwen/QwQ-32B\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\nERROR:serverless_models.text_models.test_qwq_32b:\u274c QwQ-32B text test failed: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=Qwen/QwQ-32B\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.text_models.test_qwq_32b:test_qwq_32b.py:9 \ud83d\ude80 Starting QwQ-32B text test with simple prompt\nINFO     api_clients.text_models:text_models.py:28 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.text_models.test_qwq_32b:test_qwq_32b.py:13 \u2705 TextModelsAPI instance created successfully\nINFO     api_clients.text_models:text_models.py:151 Calling qwq-32b with text prompt\nERROR    api_clients.text_models:text_models.py:173 Request failed with status 403: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=Qwen/QwQ-32B\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\nERROR    serverless_models.text_models.test_qwq_32b:test_qwq_32b.py:40 \u274c QwQ-32B text test failed: API request failed: 403 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.APIError: APIError: OpenrouterException - {\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Key limit exceeded. Manage it using https://openrouter.ai/settings/keys\\&amp;quot;,\\&amp;quot;code\\&amp;quot;:403}}. Received Model Group=Qwen/QwQ-32B\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;403&amp;quot;}}\n\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>