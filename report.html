<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <style type="text/css">body {
  font-family: Helvetica, Arial, sans-serif;
  font-size: 12px;
  /* do not increase min-width as some may use split screens */
  min-width: 800px;
  color: #999;
}

h1 {
  font-size: 24px;
  color: black;
}

h2 {
  font-size: 16px;
  color: black;
}

p {
  color: black;
}

a {
  color: #999;
}

table {
  border-collapse: collapse;
}

/******************************
 * SUMMARY INFORMATION
 ******************************/
#environment td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  vertical-align: top;
}
#environment tr:nth-child(odd) {
  background-color: #f6f6f6;
}
#environment ul {
  margin: 0;
  padding: 0 20px;
}

/******************************
 * TEST RESULT COLORS
 ******************************/
span.passed,
.passed .col-result {
  color: green;
}

span.skipped,
span.xfailed,
span.rerun,
.skipped .col-result,
.xfailed .col-result,
.rerun .col-result {
  color: orange;
}

span.error,
span.failed,
span.xpassed,
.error .col-result,
.failed .col-result,
.xpassed .col-result {
  color: red;
}

.col-links__extra {
  margin-right: 3px;
}

/******************************
 * RESULTS TABLE
 *
 * 1. Table Layout
 * 2. Extra
 * 3. Sorting items
 *
 ******************************/
/*------------------
 * 1. Table Layout
 *------------------*/
#results-table {
  border: 1px solid #e6e6e6;
  color: #999;
  font-size: 12px;
  width: 100%;
}
#results-table th,
#results-table td {
  padding: 5px;
  border: 1px solid #e6e6e6;
  text-align: left;
}
#results-table th {
  font-weight: bold;
}

/*------------------
 * 2. Extra
 *------------------*/
.logwrapper {
  max-height: 230px;
  overflow-y: scroll;
  background-color: #e6e6e6;
}
.logwrapper.expanded {
  max-height: none;
}
.logwrapper.expanded .logexpander:after {
  content: "collapse [-]";
}
.logwrapper .logexpander {
  z-index: 1;
  position: sticky;
  top: 10px;
  width: max-content;
  border: 1px solid;
  border-radius: 3px;
  padding: 5px 7px;
  margin: 10px 0 10px calc(100% - 80px);
  cursor: pointer;
  background-color: #e6e6e6;
}
.logwrapper .logexpander:after {
  content: "expand [+]";
}
.logwrapper .logexpander:hover {
  color: #000;
  border-color: #000;
}
.logwrapper .log {
  min-height: 40px;
  position: relative;
  top: -50px;
  height: calc(100% + 50px);
  border: 1px solid #e6e6e6;
  color: black;
  display: block;
  font-family: "Courier New", Courier, monospace;
  padding: 5px;
  padding-right: 80px;
  white-space: pre-wrap;
}

div.media {
  border: 1px solid #e6e6e6;
  float: right;
  height: 240px;
  margin: 0 5px;
  overflow: hidden;
  width: 320px;
}

.media-container {
  display: grid;
  grid-template-columns: 25px auto 25px;
  align-items: center;
  flex: 1 1;
  overflow: hidden;
  height: 200px;
}

.media-container--fullscreen {
  grid-template-columns: 0px auto 0px;
}

.media-container__nav--right,
.media-container__nav--left {
  text-align: center;
  cursor: pointer;
}

.media-container__viewport {
  cursor: pointer;
  text-align: center;
  height: inherit;
}
.media-container__viewport img,
.media-container__viewport video {
  object-fit: cover;
  width: 100%;
  max-height: 100%;
}

.media__name,
.media__counter {
  display: flex;
  flex-direction: row;
  justify-content: space-around;
  flex: 0 0 25px;
  align-items: center;
}

.collapsible td:not(.col-links) {
  cursor: pointer;
}
.collapsible td:not(.col-links):hover::after {
  color: #bbb;
  font-style: italic;
  cursor: pointer;
}

.col-result {
  width: 130px;
}
.col-result:hover::after {
  content: " (hide details)";
}

.col-result.collapsed:hover::after {
  content: " (show details)";
}

#environment-header h2:hover::after {
  content: " (hide details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

#environment-header.collapsed h2:hover::after {
  content: " (show details)";
  color: #bbb;
  font-style: italic;
  cursor: pointer;
  font-size: 12px;
}

/*------------------
 * 3. Sorting items
 *------------------*/
.sortable {
  cursor: pointer;
}
.sortable.desc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: -12.5px;
  border: 10px solid #4caf50;
  border-bottom: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}
.sortable.asc:after {
  content: " ";
  position: relative;
  left: 5px;
  bottom: 12.5px;
  border: 10px solid #4caf50;
  border-top: 0;
  border-left-color: transparent;
  border-right-color: transparent;
}

.hidden, .summary__reload__button.hidden {
  display: none;
}

.summary__data {
  flex: 0 0 550px;
}
.summary__reload {
  flex: 1 1;
  display: flex;
  justify-content: center;
}
.summary__reload__button {
  flex: 0 0 300px;
  display: flex;
  color: white;
  font-weight: bold;
  background-color: #4caf50;
  text-align: center;
  justify-content: center;
  align-items: center;
  border-radius: 3px;
  cursor: pointer;
}
.summary__reload__button:hover {
  background-color: #46a049;
}
.summary__spacer {
  flex: 0 0 550px;
}

.controls {
  display: flex;
  justify-content: space-between;
}

.filters,
.collapse {
  display: flex;
  align-items: center;
}
.filters button,
.collapse button {
  color: #999;
  border: none;
  background: none;
  cursor: pointer;
  text-decoration: underline;
}
.filters button:hover,
.collapse button:hover {
  color: #ccc;
}

.filter__label {
  margin-right: 10px;
}

      </style>
    
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 03-Sep-2025 at 17:25:51 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">7 tests took 00:00:56.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">1 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">6 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.9.6&#34;, &#34;Platform&#34;: &#34;macOS-15.5-arm64-arm-64bit&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;8.4.1&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;html&#34;: &#34;4.1.1&#34;, &#34;asyncio&#34;: &#34;1.1.0&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;, &#34;allure-pytest&#34;: &#34;2.13.2&#34;}}, &#34;tests&#34;: {&#34;tests/serverless_models/multimodal_models/test_claude_sonnet4.py::test_new_claude_sonnet4&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_claude_sonnet4.py::test_new_claude_sonnet4&#34;, &#34;duration&#34;: &#34;00:00:06&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_claude_sonnet4.py::test_new_claude_sonnet4&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:06&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;config_with_api_key = {&amp;#x27;api_key&amp;#x27;: &amp;#x27;sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;base_url&amp;#x27;: &amp;#x27;https://dev-portal-api.nebulablock.com/api/v1&amp;#x27;, &amp;#x27;chat_completion...roxy.nebulablock.com/v1/chat/completions&amp;#x27;, &amp;#x27;embedding_url&amp;#x27;: &amp;#x27;https://dev-llm-proxy.nebulablock.com/v1/embeddings&amp;#x27;, ...}\n\n    def test_new_claude_sonnet4(config_with_api_key):\n        logger.info(&amp;quot;\ud83d\ude80 Starting Claude Sonnet 4 test with simple prompt&amp;quot;)\n    \n        try:\n            multimodal_api = MultimodalModelsAPI(config_with_api_key)\n            logger.info(&amp;quot;\u2705 MultimodalModelsAPI instance created successfully&amp;quot;)\n    \n&amp;gt;           response = multimodal_api.call_model(\n                model_name=&amp;quot;claude-sonnet-4&amp;quot;,\n                prompt=&amp;quot;Hello&amp;quot;,\n                system_message=&amp;quot;You are a helpful assistant.&amp;quot;\n            )\n\ntests/serverless_models/multimodal_models/test_claude_sonnet4.py:16: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;api_clients.multimodal_models.MultimodalModelsAPI object at 0x104db9f10&amp;gt;\nmodel_name = &amp;#x27;claude-sonnet-4&amp;#x27;, prompt = &amp;#x27;Hello&amp;#x27;, images = None\nsystem_message = &amp;#x27;You are a helpful assistant.&amp;#x27;, kwargs = {}\nmodel_config = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;model&amp;#x27;: &amp;#x27;anthropic/claude-sonnet-4-20250514&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, &amp;#x27;temperature&amp;#x27;: 1, ...}\nmessages = [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Hello&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}]\npayload = {&amp;#x27;max_tokens&amp;#x27;: None, &amp;#x27;messages&amp;#x27;: [{&amp;#x27;content&amp;#x27;: &amp;#x27;You are a helpful assistant.&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;system&amp;#x27;}, {&amp;#x27;content&amp;#x27;: &amp;#x27;Hello&amp;#x27;, &amp;#x27;role&amp;#x27;: &amp;#x27;user&amp;#x27;}], &amp;#x27;model&amp;#x27;: &amp;#x27;anthropic/claude-sonnet-4-20250514&amp;#x27;, &amp;#x27;stream&amp;#x27;: False, ...}\nheaders = {&amp;#x27;Authorization&amp;#x27;: &amp;#x27;Bearer sk-Mh-GUPll-dGOiFBM2IQAxA&amp;#x27;, &amp;#x27;Content-Type&amp;#x27;: &amp;#x27;application/json&amp;#x27;}\n\n    def call_model(\n        self,\n        model_name: str,\n        prompt: str,\n        images: Optional[List[str]] = None,\n        system_message: Optional[str] = None,\n        **kwargs\n    ) -&amp;gt; Dict[str, Any]:\n        &amp;quot;&amp;quot;&amp;quot;\n        Call multimodal model with text and optional images.\n    \n        Args:\n            model_name: Model identifier (e.g., &amp;#x27;claude-sonnet-4&amp;#x27;, &amp;#x27;gpt-4o-mini&amp;#x27;)\n            prompt: Text prompt\n            images: Optional list of image paths, URLs, or base64 strings\n            system_message: Optional system message\n            **kwargs: Override default model parameters\n    \n        Returns:\n            API response dictionary\n        &amp;quot;&amp;quot;&amp;quot;\n        # Get model configuration\n        model_config = self._get_model_config(model_name)\n        if not model_config:\n            raise ValueError(f&amp;quot;Unknown model: {model_name}&amp;quot;)\n    \n        # Build messages\n        messages = []\n        if system_message:\n            messages.append({&amp;quot;role&amp;quot;: &amp;quot;system&amp;quot;, &amp;quot;content&amp;quot;: system_message})\n    \n        # Build user content\n        if images:\n            # Multimodal content (text + images)\n            content = []\n            if prompt:\n                content.append({&amp;quot;type&amp;quot;: &amp;quot;text&amp;quot;, &amp;quot;text&amp;quot;: prompt})\n    \n            for image in images:\n                image_content = self._process_image_input(image)\n                content.append(image_content)\n    \n            messages.append({&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: content})\n            self.logger.info(f&amp;quot;Calling {model_name} with text prompt and {len(images)} images&amp;quot;)\n        else:\n            # Text-only content\n            messages.append({&amp;quot;role&amp;quot;: &amp;quot;user&amp;quot;, &amp;quot;content&amp;quot;: prompt})\n            self.logger.info(f&amp;quot;Calling {model_name} with text prompt&amp;quot;)\n    \n        # Merge default config with overrides\n        payload = {**model_config, &amp;quot;messages&amp;quot;: messages, **kwargs}\n    \n        # Make direct request since we have full URL\n        headers = {\n            &amp;quot;Authorization&amp;quot;: f&amp;quot;Bearer {self.api_key}&amp;quot;,\n            &amp;quot;Content-Type&amp;quot;: &amp;quot;application/json&amp;quot;\n        }\n    \n        self.logger.debug(f&amp;quot;Making request to: {self.base_model_url}&amp;quot;)\n        self.logger.debug(f&amp;quot;Headers: {headers}&amp;quot;)\n        self.logger.debug(f&amp;quot;Payload: {payload}&amp;quot;)\n    \n        response = requests.post(self.base_model_url, headers=headers, json=payload)\n    \n        # Log response for debugging\n        self.logger.debug(f&amp;quot;Response status: {response.status_code}&amp;quot;)\n        self.logger.debug(f&amp;quot;Response headers: {dict(response.headers)}&amp;quot;)\n    \n        if response.status_code != 200:\n            self.logger.error(f&amp;quot;Request failed with status {response.status_code}: {response.text}&amp;quot;)\n&amp;gt;           raise Exception(f&amp;quot;API request failed: {response.status_code} - {response.text}&amp;quot;)\nE           Exception: API request failed: 400 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.BadRequestError: AnthropicException - {\\&amp;quot;type\\&amp;quot;:\\&amp;quot;error\\&amp;quot;,\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;type\\&amp;quot;:\\&amp;quot;invalid_request_error\\&amp;quot;,\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Your credit balance is too low to access the Anthropic API. Please go to Plans &amp;amp; Billing to upgrade or purchase credits.\\&amp;quot;},\\&amp;quot;request_id\\&amp;quot;:\\&amp;quot;req_011CSmJeZUZJFz2JTQfKf7Xa\\&amp;quot;}. Received Model Group=anthropic/claude-sonnet-4-20250514\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;400&amp;quot;}}\n\napi_clients/multimodal_models.py:147: Exception\n\n---------------------------- Captured stderr setup -----------------------------\nINFO:conftest:\u2705 Loaded configuration from config.yaml\nINFO:conftest:[pytest] Using user from CLI: Member7 -&amp;gt; thivunguyen1506+member7@gmail.com\nINFO:conftest:Login once for entire test session with user: thivunguyen1506+member7@gmail.com\nINFO:conftest:\u2705 Login successful - token will be reused for all tests\nINFO:conftest:Found 1 API keys for user\nINFO:conftest:Found 1 personal API keys\nINFO:conftest:Found personal API key: Unnamed (ID: 348)\nINFO:conftest:\u2705 Using API key from logged-in user\n\n------------------------------ Captured log setup ------------------------------\nINFO     conftest:conftest.py:50 \u2705 Loaded configuration from config.yaml\nINFO     conftest:conftest.py:108 [pytest] Using user from CLI: Member7 -&amp;gt; thivunguyen1506+member7@gmail.com\nINFO     conftest:conftest.py:133 Login once for entire test session with user: thivunguyen1506+member7@gmail.com\nINFO     conftest:conftest.py:141 \u2705 Login successful - token will be reused for all tests\nINFO     conftest:conftest.py:194 Found 1 API keys for user\nINFO     conftest:conftest.py:238 Found 1 personal API keys\nINFO     conftest:conftest.py:203 Found personal API key: Unnamed (ID: 348)\nINFO     conftest:conftest.py:92 \u2705 Using API key from logged-in user\n\n----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_claude_sonnet4:\ud83d\ude80 Starting Claude Sonnet 4 test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_claude_sonnet4:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling claude-sonnet-4 with text prompt\nERROR:api_clients.multimodal_models:Request failed with status 400: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.BadRequestError: AnthropicException - {\\&amp;quot;type\\&amp;quot;:\\&amp;quot;error\\&amp;quot;,\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;type\\&amp;quot;:\\&amp;quot;invalid_request_error\\&amp;quot;,\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Your credit balance is too low to access the Anthropic API. Please go to Plans &amp;amp; Billing to upgrade or purchase credits.\\&amp;quot;},\\&amp;quot;request_id\\&amp;quot;:\\&amp;quot;req_011CSmJeZUZJFz2JTQfKf7Xa\\&amp;quot;}. Received Model Group=anthropic/claude-sonnet-4-20250514\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;400&amp;quot;}}\nERROR:serverless_models.multimodal_models.test_claude_sonnet4:\u274c Claude Sonnet 4 test failed: API request failed: 400 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.BadRequestError: AnthropicException - {\\&amp;quot;type\\&amp;quot;:\\&amp;quot;error\\&amp;quot;,\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;type\\&amp;quot;:\\&amp;quot;invalid_request_error\\&amp;quot;,\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Your credit balance is too low to access the Anthropic API. Please go to Plans &amp;amp; Billing to upgrade or purchase credits.\\&amp;quot;},\\&amp;quot;request_id\\&amp;quot;:\\&amp;quot;req_011CSmJeZUZJFz2JTQfKf7Xa\\&amp;quot;}. Received Model Group=anthropic/claude-sonnet-4-20250514\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;400&amp;quot;}}\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_claude_sonnet4:test_claude_sonnet4.py:10 \ud83d\ude80 Starting Claude Sonnet 4 test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_claude_sonnet4:test_claude_sonnet4.py:14 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling claude-sonnet-4 with text prompt\nERROR    api_clients.multimodal_models:multimodal_models.py:146 Request failed with status 400: {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.BadRequestError: AnthropicException - {\\&amp;quot;type\\&amp;quot;:\\&amp;quot;error\\&amp;quot;,\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;type\\&amp;quot;:\\&amp;quot;invalid_request_error\\&amp;quot;,\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Your credit balance is too low to access the Anthropic API. Please go to Plans &amp;amp; Billing to upgrade or purchase credits.\\&amp;quot;},\\&amp;quot;request_id\\&amp;quot;:\\&amp;quot;req_011CSmJeZUZJFz2JTQfKf7Xa\\&amp;quot;}. Received Model Group=anthropic/claude-sonnet-4-20250514\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;400&amp;quot;}}\nERROR    serverless_models.multimodal_models.test_claude_sonnet4:test_claude_sonnet4.py:41 \u274c Claude Sonnet 4 test failed: API request failed: 400 - {&amp;quot;error&amp;quot;:{&amp;quot;message&amp;quot;:&amp;quot;litellm.BadRequestError: AnthropicException - {\\&amp;quot;type\\&amp;quot;:\\&amp;quot;error\\&amp;quot;,\\&amp;quot;error\\&amp;quot;:{\\&amp;quot;type\\&amp;quot;:\\&amp;quot;invalid_request_error\\&amp;quot;,\\&amp;quot;message\\&amp;quot;:\\&amp;quot;Your credit balance is too low to access the Anthropic API. Please go to Plans &amp;amp; Billing to upgrade or purchase credits.\\&amp;quot;},\\&amp;quot;request_id\\&amp;quot;:\\&amp;quot;req_011CSmJeZUZJFz2JTQfKf7Xa\\&amp;quot;}. Received Model Group=anthropic/claude-sonnet-4-20250514\\nAvailable Model Group Fallbacks=None&amp;quot;,&amp;quot;type&amp;quot;:null,&amp;quot;param&amp;quot;:null,&amp;quot;code&amp;quot;:&amp;quot;400&amp;quot;}}\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gemini_2_0_flash.py::test_gemini_2_0_flash_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gemini_2_0_flash.py::test_gemini_2_0_flash_simple&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gemini_2_0_flash.py::test_gemini_2_0_flash_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash:\ud83d\ude80 Starting Gemini 2.0 Flash test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gemini-2.0-flash with text prompt\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash:\ud83d\udcdd Gemini 2.0 Flash response: Yes, Montreal is definitely a thriving hub for the AI industry! Here&amp;#x27;s a breakdown of why:\n\n*   **Strong Academic Foundation:** Montreal boasts world-renowned universities like McGill University and the University of Montreal, which have strong AI research programs. These institutions attract top talent and produce cutting-edge research.\n*   **Government Support:** The Canadian government, as well as the Quebec provincial government, have made significant investments in AI research and development, creating a supportive ecosystem for AI companies.\n*   **Home to AI Pioneers:** Yoshua Bengio, a pioneer in deep learning, is based in Montreal. His presence and work at the Montreal Institute for Learning Algorithms (MILA) have attracted researchers and companies from around the world.\n*   **Growing Startup Ecosystem:** Montreal has a vibrant startup scene, with many AI-focused companies emerging in recent years. These startups are working on a wide range of applications, from healthcare to transportation.\n*   **Major Tech Companies:** Large tech companies like Google, Microsoft, Facebook (Meta), and Amazon have established AI research labs in Montreal, further solidifying the city&amp;#x27;s position as a leading AI hub.\n*   **Talent Pool:** The combination of strong academic programs, government support, and the presence of major tech companies has created a deep pool of AI talent in Montreal.\n*   **AI-Related Events and Conferences:** Montreal hosts several AI-related events and conferences, attracting researchers, entrepreneurs, and investors from around the globe.\n\nIn summary, Montreal has all the key ingredients for a thriving AI industry: strong academic institutions, government support, pioneering researchers, a growing startup ecosystem, and a deep pool of talent.\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash:\u2705 Gemini 2.0 Flash test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash:test_gemini_2_0_flash.py:9 \ud83d\ude80 Starting Gemini 2.0 Flash test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash:test_gemini_2_0_flash.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gemini-2.0-flash with text prompt\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash:test_gemini_2_0_flash.py:32 \ud83d\udcdd Gemini 2.0 Flash response: Yes, Montreal is definitely a thriving hub for the AI industry! Here&amp;#x27;s a breakdown of why:\n\n*   **Strong Academic Foundation:** Montreal boasts world-renowned universities like McGill University and the University of Montreal, which have strong AI research programs. These institutions attract top talent and produce cutting-edge research.\n*   **Government Support:** The Canadian government, as well as the Quebec provincial government, have made significant investments in AI research and development, creating a supportive ecosystem for AI companies.\n*   **Home to AI Pioneers:** Yoshua Bengio, a pioneer in deep learning, is based in Montreal. His presence and work at the Montreal Institute for Learning Algorithms (MILA) have attracted researchers and companies from around the world.\n*   **Growing Startup Ecosystem:** Montreal has a vibrant startup scene, with many AI-focused companies emerging in recent years. These startups are working on a wide range of applications, from healthcare to transportation.\n*   **Major Tech Companies:** Large tech companies like Google, Microsoft, Facebook (Meta), and Amazon have established AI research labs in Montreal, further solidifying the city&amp;#x27;s position as a leading AI hub.\n*   **Talent Pool:** The combination of strong academic programs, government support, and the presence of major tech companies has created a deep pool of AI talent in Montreal.\n*   **AI-Related Events and Conferences:** Montreal hosts several AI-related events and conferences, attracting researchers, entrepreneurs, and investors from around the globe.\n\nIn summary, Montreal has all the key ingredients for a thriving AI industry: strong academic institutions, government support, pioneering researchers, a growing startup ecosystem, and a deep pool of talent.\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash:test_gemini_2_0_flash.py:37 \u2705 Gemini 2.0 Flash test completed successfully\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gemini_2_0_flash_lite.py::test_gemini_2_0_flash_lite_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gemini_2_0_flash_lite.py::test_gemini_2_0_flash_lite_simple&#34;, &#34;duration&#34;: &#34;00:00:04&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gemini_2_0_flash_lite.py::test_gemini_2_0_flash_lite_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:04&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash_lite:\ud83d\ude80 Starting Gemini 2.0 Flash Lite test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash_lite:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gemini-2.0-flash-lite with text prompt\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash_lite:\ud83d\udcdd Gemini 2.0 Flash Lite response: Yes, Montreal is definitely a thriving hub for the AI industry! Here&amp;#x27;s a breakdown of why:\n\n*   **Strong Academic Presence:** Montreal is home to some of the world&amp;#x27;s leading AI research institutions, including:\n    *   **Universit\u00e9 de Montr\u00e9al:** Hosts the **Mila - Quebec Artificial Intelligence Institute**, founded by Yoshua Bengio, a pioneer in deep learning. Mila is a major driving force in AI research and development.\n    *   **McGill University:** Also has a strong AI research presence and collaborates with Mila.\n    *   **HEC Montr\u00e9al:** Offers programs related to data science and AI.\n\n*   **Government Support:** The Quebec and Canadian governments have invested heavily in AI, providing funding for research, talent development, and infrastructure. This has created a supportive ecosystem for the industry.\n\n*   **Talent Pool:** The presence of top universities and research institutions attracts and cultivates a strong pool of AI talent.\n\n*   **Startup Activity:** Montreal has seen a surge in AI startups, with companies focusing on various applications, including natural language processing, computer vision, and robotics.\n\n*   **Corporate Investment:** Major tech companies, including Google, Facebook, Microsoft, and others, have established AI research labs and offices in Montreal, drawn by the talent and ecosystem.\n\n*   **Community and Collaboration:** There is a strong sense of community and collaboration within Montreal&amp;#x27;s AI ecosystem, fostering knowledge sharing and innovation.\n\n*   **Quality of Life:** Montreal offers a high quality of life, making it an attractive place for researchers, engineers, and entrepreneurs to live and work.\n\nIn conclusion, Montreal has all the key ingredients to be a successful AI hub: top research institutions, government support, a talented workforce, corporate investment, and a vibrant startup scene.\n\nINFO:serverless_models.multimodal_models.test_gemini_2_0_flash_lite:\u2705 Gemini 2.0 Flash Lite test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash_lite:test_gemini_2_0_flash_lite.py:9 \ud83d\ude80 Starting Gemini 2.0 Flash Lite test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash_lite:test_gemini_2_0_flash_lite.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gemini-2.0-flash-lite with text prompt\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash_lite:test_gemini_2_0_flash_lite.py:32 \ud83d\udcdd Gemini 2.0 Flash Lite response: Yes, Montreal is definitely a thriving hub for the AI industry! Here&amp;#x27;s a breakdown of why:\n\n*   **Strong Academic Presence:** Montreal is home to some of the world&amp;#x27;s leading AI research institutions, including:\n    *   **Universit\u00e9 de Montr\u00e9al:** Hosts the **Mila - Quebec Artificial Intelligence Institute**, founded by Yoshua Bengio, a pioneer in deep learning. Mila is a major driving force in AI research and development.\n    *   **McGill University:** Also has a strong AI research presence and collaborates with Mila.\n    *   **HEC Montr\u00e9al:** Offers programs related to data science and AI.\n\n*   **Government Support:** The Quebec and Canadian governments have invested heavily in AI, providing funding for research, talent development, and infrastructure. This has created a supportive ecosystem for the industry.\n\n*   **Talent Pool:** The presence of top universities and research institutions attracts and cultivates a strong pool of AI talent.\n\n*   **Startup Activity:** Montreal has seen a surge in AI startups, with companies focusing on various applications, including natural language processing, computer vision, and robotics.\n\n*   **Corporate Investment:** Major tech companies, including Google, Facebook, Microsoft, and others, have established AI research labs and offices in Montreal, drawn by the talent and ecosystem.\n\n*   **Community and Collaboration:** There is a strong sense of community and collaboration within Montreal&amp;#x27;s AI ecosystem, fostering knowledge sharing and innovation.\n\n*   **Quality of Life:** Montreal offers a high quality of life, making it an attractive place for researchers, engineers, and entrepreneurs to live and work.\n\nIn conclusion, Montreal has all the key ingredients to be a successful AI hub: top research institutions, government support, a talented workforce, corporate investment, and a vibrant startup scene.\n\nINFO     serverless_models.multimodal_models.test_gemini_2_0_flash_lite:test_gemini_2_0_flash_lite.py:37 \u2705 Gemini 2.0 Flash Lite test completed successfully\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_flash.py::test_gemini_2_5_flash_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_flash.py::test_gemini_2_5_flash_simple&#34;, &#34;duration&#34;: &#34;00:00:11&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gemini_2_5_flash.py::test_gemini_2_5_flash_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:11&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash:\ud83d\ude80 Starting Gemini 2.5 Flash test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gemini-2.5-flash with text prompt\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash:\ud83d\udcdd Gemini 2.5 Flash response: Absolutely, Montreal is widely recognized as one of the leading global hubs for the AI industry. It has cemented its position through a combination of world-class academic research, significant industry investment, strong government support, and a vibrant startup ecosystem.\n\nHere&amp;#x27;s why it&amp;#x27;s considered a thriving hub:\n\n1.  **Academic Excellence &amp;amp; Research Powerhouse:**\n    *   **Mila (Quebec Artificial Intelligence Institute):** This is the crown jewel. Led by Yoshua Bengio (a Turing Award laureate, often called one of the &amp;quot;Godfathers of AI&amp;quot;), Mila is the world&amp;#x27;s largest academic research center in deep learning. It attracts top talent from around the globe.\n    *   **Universities:** McGill University and the Universit\u00e9 de Montr\u00e9al (UdeM) are at the forefront of AI research, producing a steady stream of highly skilled graduates (PhDs, post-docs, and masters) who feed the industry.\n\n2.  **Major Tech Company Presence:**\n    *   Many global tech giants have established AI research labs and offices in Montreal to tap into the local talent and collaborate with Mila and universities. These include:\n        *   **Google Brain / Google AI**\n        *   **Meta AI (FAIR)**\n        *   **Microsoft Research**\n        *   **IBM Research**\n        *   **Samsung AI Center**\n        *   **Huawei**\n        *   **DeepMind** (though some have scaled back their initial large expansions, the core presence and collaboration remain).\n\n3.  **Vibrant Startup Ecosystem:**\n    *   Montreal boasts a significant number of AI startups, ranging from those developing foundational AI technologies to those applying AI in various sectors like healthcare, finance, gaming, and manufacturing.\n    *   Organizations like **IVADO** (Institute for Data Valorization) help bridge the gap between academic research and industry application, fostering innovation and commercialization.\n\n4.  **Government Support and Investment:**\n    *   **Pan-Canadian AI Strategy:** Canada was the first G7 country to announce a national AI strategy, with significant funding allocated to its three AI &amp;quot;superclusters&amp;quot; \u2013 Montreal (Mila), Toronto-Waterloo (Vector Institute), and Edmonton (Amii).\n    *   **Quebec AI Strategy:** The provincial government has also heavily invested in AI, offering incentives and programs to attract and retain AI companies and talent.\n    *   **Tax Credits:** Favorable tax credits for R&amp;amp;D in Quebec also make it an attractive place for tech companies.\n\n5.  **Talent Pool and Quality of Life:**\n    *   The city has a large, diverse, and multilingual talent pool, making it easier for companies to find skilled employees.\n    *   Compared to other major tech hubs (like Silicon Valley or New York), Montreal offers a relatively lower cost of living, vibrant cultural scene, and high quality of life, which helps attract and retain talent.\n\n**In summary:** Yes, Montreal is undoubtedly a thriving hub for the AI industry. Its unique blend of pioneering academic research, strong industry investment, and robust government support has created a dynamic ecosystem that continues to attract talent and drive innovation in artificial intelligence.\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash:\u2705 Gemini 2.5 Flash test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash:test_gemini_2_5_flash.py:9 \ud83d\ude80 Starting Gemini 2.5 Flash test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash:test_gemini_2_5_flash.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gemini-2.5-flash with text prompt\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash:test_gemini_2_5_flash.py:32 \ud83d\udcdd Gemini 2.5 Flash response: Absolutely, Montreal is widely recognized as one of the leading global hubs for the AI industry. It has cemented its position through a combination of world-class academic research, significant industry investment, strong government support, and a vibrant startup ecosystem.\n\nHere&amp;#x27;s why it&amp;#x27;s considered a thriving hub:\n\n1.  **Academic Excellence &amp;amp; Research Powerhouse:**\n    *   **Mila (Quebec Artificial Intelligence Institute):** This is the crown jewel. Led by Yoshua Bengio (a Turing Award laureate, often called one of the &amp;quot;Godfathers of AI&amp;quot;), Mila is the world&amp;#x27;s largest academic research center in deep learning. It attracts top talent from around the globe.\n    *   **Universities:** McGill University and the Universit\u00e9 de Montr\u00e9al (UdeM) are at the forefront of AI research, producing a steady stream of highly skilled graduates (PhDs, post-docs, and masters) who feed the industry.\n\n2.  **Major Tech Company Presence:**\n    *   Many global tech giants have established AI research labs and offices in Montreal to tap into the local talent and collaborate with Mila and universities. These include:\n        *   **Google Brain / Google AI**\n        *   **Meta AI (FAIR)**\n        *   **Microsoft Research**\n        *   **IBM Research**\n        *   **Samsung AI Center**\n        *   **Huawei**\n        *   **DeepMind** (though some have scaled back their initial large expansions, the core presence and collaboration remain).\n\n3.  **Vibrant Startup Ecosystem:**\n    *   Montreal boasts a significant number of AI startups, ranging from those developing foundational AI technologies to those applying AI in various sectors like healthcare, finance, gaming, and manufacturing.\n    *   Organizations like **IVADO** (Institute for Data Valorization) help bridge the gap between academic research and industry application, fostering innovation and commercialization.\n\n4.  **Government Support and Investment:**\n    *   **Pan-Canadian AI Strategy:** Canada was the first G7 country to announce a national AI strategy, with significant funding allocated to its three AI &amp;quot;superclusters&amp;quot; \u2013 Montreal (Mila), Toronto-Waterloo (Vector Institute), and Edmonton (Amii).\n    *   **Quebec AI Strategy:** The provincial government has also heavily invested in AI, offering incentives and programs to attract and retain AI companies and talent.\n    *   **Tax Credits:** Favorable tax credits for R&amp;amp;D in Quebec also make it an attractive place for tech companies.\n\n5.  **Talent Pool and Quality of Life:**\n    *   The city has a large, diverse, and multilingual talent pool, making it easier for companies to find skilled employees.\n    *   Compared to other major tech hubs (like Silicon Valley or New York), Montreal offers a relatively lower cost of living, vibrant cultural scene, and high quality of life, which helps attract and retain talent.\n\n**In summary:** Yes, Montreal is undoubtedly a thriving hub for the AI industry. Its unique blend of pioneering academic research, strong industry investment, and robust government support has created a dynamic ecosystem that continues to attract talent and drive innovation in artificial intelligence.\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash:test_gemini_2_5_flash.py:37 \u2705 Gemini 2.5 Flash test completed successfully\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_flash_lite.py::test_gemini_2_5_flash_lite_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_flash_lite.py::test_gemini_2_5_flash_lite_simple&#34;, &#34;duration&#34;: &#34;00:00:03&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gemini_2_5_flash_lite.py::test_gemini_2_5_flash_lite_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:03&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash_lite:\ud83d\ude80 Starting Gemini 2.5 Flash Lite test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash_lite:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gemini-2.5-flash-lite with text prompt\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash_lite:\ud83d\udcdd Gemini 2.5 Flash Lite response: Yes, Montreal is widely recognized as a **thriving and significant hub for the AI industry**. It has earned this reputation through a combination of factors, making it a leading global center for AI research, development, and talent.\n\nHere&amp;#x27;s why Montreal is considered a thriving AI hub:\n\n*   **World-Class Research Institutions:** Montreal is home to some of the most influential AI research labs and universities in the world.\n    *   **Mila \u2013 Quebec AI Institute:** This is perhaps the most prominent factor. Founded by Yoshua Bengio, one of the &amp;quot;godfathers of AI,&amp;quot; Mila is a leading research institute dedicated to deep learning. It attracts top researchers and students, fostering groundbreaking advancements.\n    *   **University of Montreal and McGill University:** Both universities have strong AI programs and contribute significantly to research and talent development. They have numerous professors and labs focused on various aspects of AI.\n\n*   **Strong Talent Pool:** The concentration of top-tier research institutions naturally creates a deep and skilled talent pool. Montreal produces a large number of AI researchers, engineers, and data scientists who are highly sought after by companies worldwide.\n\n*   **Significant Industry Presence:** Many major tech companies have established significant AI research and development centers in Montreal, drawn by the talent and research ecosystem. This includes:\n    *   **Google Brain / Google AI**\n    *   **Microsoft**\n    *   **Nvidia**\n    *   **Facebook AI Research (FAIR)**\n    *   **Amazon**\n    *   **IBM**\n    *   **OpenAI** (While not a physical office in the same way as the others, their influence and the talent they attract are felt)\n\n*   **Government Support and Investment:** The Canadian and Quebec governments have recognized the importance of AI and have invested heavily in the sector. This includes funding for research, talent development programs, and initiatives to support AI startups.\n\n*   **Vibrant Startup Ecosystem:** Beyond the large tech giants, Montreal boasts a growing number of AI startups across various sectors, including healthcare, finance, transportation, and creative industries. This entrepreneurial spirit contributes to the dynamism of the hub.\n\n*   **Collaborative Environment:** The presence of research institutions, established companies, and startups fosters a collaborative environment where knowledge sharing and partnerships are common. This accelerates innovation and growth.\n\n*   **International Recognition:** Montreal consistently ranks among the top global cities for AI talent and research output, solidifying its position as a leader in the field.\n\n**In summary, Montreal is not just a participant but a driving force in the global AI revolution. Its strengths lie in its unparalleled research capabilities, its ability to attract and retain top talent, and the supportive ecosystem created by both public and private sectors.**\nINFO:serverless_models.multimodal_models.test_gemini_2_5_flash_lite:\u2705 Gemini 2.5 Flash Lite test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash_lite:test_gemini_2_5_flash_lite.py:9 \ud83d\ude80 Starting Gemini 2.5 Flash Lite test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash_lite:test_gemini_2_5_flash_lite.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gemini-2.5-flash-lite with text prompt\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash_lite:test_gemini_2_5_flash_lite.py:32 \ud83d\udcdd Gemini 2.5 Flash Lite response: Yes, Montreal is widely recognized as a **thriving and significant hub for the AI industry**. It has earned this reputation through a combination of factors, making it a leading global center for AI research, development, and talent.\n\nHere&amp;#x27;s why Montreal is considered a thriving AI hub:\n\n*   **World-Class Research Institutions:** Montreal is home to some of the most influential AI research labs and universities in the world.\n    *   **Mila \u2013 Quebec AI Institute:** This is perhaps the most prominent factor. Founded by Yoshua Bengio, one of the &amp;quot;godfathers of AI,&amp;quot; Mila is a leading research institute dedicated to deep learning. It attracts top researchers and students, fostering groundbreaking advancements.\n    *   **University of Montreal and McGill University:** Both universities have strong AI programs and contribute significantly to research and talent development. They have numerous professors and labs focused on various aspects of AI.\n\n*   **Strong Talent Pool:** The concentration of top-tier research institutions naturally creates a deep and skilled talent pool. Montreal produces a large number of AI researchers, engineers, and data scientists who are highly sought after by companies worldwide.\n\n*   **Significant Industry Presence:** Many major tech companies have established significant AI research and development centers in Montreal, drawn by the talent and research ecosystem. This includes:\n    *   **Google Brain / Google AI**\n    *   **Microsoft**\n    *   **Nvidia**\n    *   **Facebook AI Research (FAIR)**\n    *   **Amazon**\n    *   **IBM**\n    *   **OpenAI** (While not a physical office in the same way as the others, their influence and the talent they attract are felt)\n\n*   **Government Support and Investment:** The Canadian and Quebec governments have recognized the importance of AI and have invested heavily in the sector. This includes funding for research, talent development programs, and initiatives to support AI startups.\n\n*   **Vibrant Startup Ecosystem:** Beyond the large tech giants, Montreal boasts a growing number of AI startups across various sectors, including healthcare, finance, transportation, and creative industries. This entrepreneurial spirit contributes to the dynamism of the hub.\n\n*   **Collaborative Environment:** The presence of research institutions, established companies, and startups fosters a collaborative environment where knowledge sharing and partnerships are common. This accelerates innovation and growth.\n\n*   **International Recognition:** Montreal consistently ranks among the top global cities for AI talent and research output, solidifying its position as a leader in the field.\n\n**In summary, Montreal is not just a participant but a driving force in the global AI revolution. Its strengths lie in its unparalleled research capabilities, its ability to attract and retain top talent, and the supportive ecosystem created by both public and private sectors.**\nINFO     serverless_models.multimodal_models.test_gemini_2_5_flash_lite:test_gemini_2_5_flash_lite.py:37 \u2705 Gemini 2.5 Flash Lite test completed successfully\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_pro.py::test_gemini_2_5_pro_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gemini_2_5_pro.py::test_gemini_2_5_pro_simple&#34;, &#34;duration&#34;: &#34;00:00:25&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gemini_2_5_pro.py::test_gemini_2_5_pro_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:25&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gemini_2_5_pro:\ud83d\ude80 Starting Gemini 2.5 Pro test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gemini_2_5_pro:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gemini-2.5-pro with text prompt\nINFO:serverless_models.multimodal_models.test_gemini_2_5_pro:\ud83d\udcdd Gemini 2.5 Pro response: Yes, absolutely. **Montreal is unquestionably one of the world&amp;#x27;s most important and thriving hubs for the Artificial Intelligence industry.**\n\nIt&amp;#x27;s not just a regional player; it&amp;#x27;s a global powerhouse, often mentioned in the same breath as Silicon Valley, Toronto, London, and Beijing when discussing top AI ecosystems.\n\nWhat makes Montreal such a dominant force is a unique and self-reinforcing combination of academic leadership, a deep talent pool, significant corporate investment, and strong government support.\n\nHere\u2019s a breakdown of the key pillars that make Montreal&amp;#x27;s AI ecosystem so successful:\n\n### 1. World-Class Academic &amp;amp; Research Foundation\n\nThis is the cornerstone of Montreal&amp;#x27;s AI dominance.\n\n*   **Yoshua Bengio:** Montreal is home to one of the three &amp;quot;godfathers of deep learning,&amp;quot; Yoshua Bengio (along with Geoffrey Hinton in Toronto and Yann LeCun at Meta/NYU). His 2018 Turing Award win cemented his and the city&amp;#x27;s reputation.\n*   **Mila (Quebec AI Institute):** Founded by Bengio, Mila is the world&amp;#x27;s largest academic deep learning research center. It brings together hundreds of top-tier researchers, post-docs, and students from the Universit\u00e9 de Montr\u00e9al and McGill University, creating an unparalleled concentration of brainpower.\n*   **IVADO:** The Institute for Data Valorization is another key player, focusing on applying data science, operational research, and AI to solve real-world problems in partnership with industry.\n\nThis academic excellence creates a **virtuous cycle**: it attracts the brightest minds from around the world to study and research, who then form the talent pool that feeds the rest of the ecosystem.\n\n### 2. A Critical Mass of Talent\n\nDirectly resulting from its academic strength, Montreal has one of the highest concentrations of AI researchers and PhD students on the planet. This deep talent pool is the primary reason why major corporations and startups flock to the city.\n\n### 3. Strong Corporate Presence (The &amp;quot;Big Tech&amp;quot; Stamp of Approval)\n\nGlobal tech giants have established major AI research labs in Montreal specifically to tap into this talent and collaborate with the academic community. This includes:\n\n*   **Google** (DeepMind lab)\n*   **Meta** (Facebook AI Research - FAIR lab)\n*   **Microsoft** Research\n*   **IBM**\n*   **Samsung** AI Centre\n*   **Thales**\n\nThe presence of these companies provides high-quality jobs, validates the city&amp;#x27;s importance, and keeps top talent from leaving.\n\n### 4. A Vibrant and Growing Startup Ecosystem\n\nMontreal is a fertile ground for AI startups. While it had a high-profile &amp;quot;cautionary tale&amp;quot; with Element AI (a massively funded startup that was ultimately acquired by ServiceNow), the ecosystem is robust and continues to produce innovative companies. Success stories and promising startups include:\n\n*   **Hopper:** A travel-tech company that uses AI for fare prediction.\n*   **Dialogue:** A virtual healthcare platform heavily utilizing AI.\n*   **Coveo:** An AI-powered search and recommendation platform.\n\nIncubators, accelerators, and venture capital funds dedicated to AI are abundant, fostering the next generation of companies.\n\n### 5. Significant and Sustained Government Support\n\nBoth the Canadian federal government and the Quebec provincial government have strategically invested hundreds of millions of dollars to build and sustain this ecosystem. The **Pan-Canadian Artificial Intelligence Strategy** was the first national AI strategy in the world, and it designated Montreal (via Mila) as one of its three primary centers of excellence. This public funding has been crucial for attracting and retaining top academic talent.\n\n### What Makes Montreal&amp;#x27;s AI Hub Unique?\n\n*   **Focus on Deep Learning:** While other cities have broad AI industries, Montreal&amp;#x27;s identity is deeply rooted in fundamental deep learning research.\n*   **Collaborative and Ethical Focus:** Led by Yoshua Bengio, there is a strong emphasis on developing AI for the common good. The **Montreal Declaration for a Responsible Development of Artificial Intelligence** is a landmark example of the community&amp;#x27;s commitment to ethics.\n*   **Affordable Quality of Life:** Compared to other major tech hubs like the San Francisco Bay Area, Montreal offers a much lower cost of living and a high quality of life, making it attractive for talent.\n*   **Cultural and Linguistic Diversity:** Its bilingual, multicultural, and European-influenced character gives it a unique and creative atmosphere.\n\n### Conclusion\n\nMontreal isn&amp;#x27;t just a city with a few AI companies; it is a **fully integrated ecosystem** where academia, industry, and government work in synergy. Its reputation as a foundational research center for deep learning gives it a unique and durable advantage, making it a **thriving, top-tier global hub for the AI industry.**\nINFO:serverless_models.multimodal_models.test_gemini_2_5_pro:\u2705 Gemini 2.5 Pro test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gemini_2_5_pro:test_gemini_2_5_pro.py:9 \ud83d\ude80 Starting Gemini 2.5 Pro test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gemini_2_5_pro:test_gemini_2_5_pro.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gemini-2.5-pro with text prompt\nINFO     serverless_models.multimodal_models.test_gemini_2_5_pro:test_gemini_2_5_pro.py:32 \ud83d\udcdd Gemini 2.5 Pro response: Yes, absolutely. **Montreal is unquestionably one of the world&amp;#x27;s most important and thriving hubs for the Artificial Intelligence industry.**\n\nIt&amp;#x27;s not just a regional player; it&amp;#x27;s a global powerhouse, often mentioned in the same breath as Silicon Valley, Toronto, London, and Beijing when discussing top AI ecosystems.\n\nWhat makes Montreal such a dominant force is a unique and self-reinforcing combination of academic leadership, a deep talent pool, significant corporate investment, and strong government support.\n\nHere\u2019s a breakdown of the key pillars that make Montreal&amp;#x27;s AI ecosystem so successful:\n\n### 1. World-Class Academic &amp;amp; Research Foundation\n\nThis is the cornerstone of Montreal&amp;#x27;s AI dominance.\n\n*   **Yoshua Bengio:** Montreal is home to one of the three &amp;quot;godfathers of deep learning,&amp;quot; Yoshua Bengio (along with Geoffrey Hinton in Toronto and Yann LeCun at Meta/NYU). His 2018 Turing Award win cemented his and the city&amp;#x27;s reputation.\n*   **Mila (Quebec AI Institute):** Founded by Bengio, Mila is the world&amp;#x27;s largest academic deep learning research center. It brings together hundreds of top-tier researchers, post-docs, and students from the Universit\u00e9 de Montr\u00e9al and McGill University, creating an unparalleled concentration of brainpower.\n*   **IVADO:** The Institute for Data Valorization is another key player, focusing on applying data science, operational research, and AI to solve real-world problems in partnership with industry.\n\nThis academic excellence creates a **virtuous cycle**: it attracts the brightest minds from around the world to study and research, who then form the talent pool that feeds the rest of the ecosystem.\n\n### 2. A Critical Mass of Talent\n\nDirectly resulting from its academic strength, Montreal has one of the highest concentrations of AI researchers and PhD students on the planet. This deep talent pool is the primary reason why major corporations and startups flock to the city.\n\n### 3. Strong Corporate Presence (The &amp;quot;Big Tech&amp;quot; Stamp of Approval)\n\nGlobal tech giants have established major AI research labs in Montreal specifically to tap into this talent and collaborate with the academic community. This includes:\n\n*   **Google** (DeepMind lab)\n*   **Meta** (Facebook AI Research - FAIR lab)\n*   **Microsoft** Research\n*   **IBM**\n*   **Samsung** AI Centre\n*   **Thales**\n\nThe presence of these companies provides high-quality jobs, validates the city&amp;#x27;s importance, and keeps top talent from leaving.\n\n### 4. A Vibrant and Growing Startup Ecosystem\n\nMontreal is a fertile ground for AI startups. While it had a high-profile &amp;quot;cautionary tale&amp;quot; with Element AI (a massively funded startup that was ultimately acquired by ServiceNow), the ecosystem is robust and continues to produce innovative companies. Success stories and promising startups include:\n\n*   **Hopper:** A travel-tech company that uses AI for fare prediction.\n*   **Dialogue:** A virtual healthcare platform heavily utilizing AI.\n*   **Coveo:** An AI-powered search and recommendation platform.\n\nIncubators, accelerators, and venture capital funds dedicated to AI are abundant, fostering the next generation of companies.\n\n### 5. Significant and Sustained Government Support\n\nBoth the Canadian federal government and the Quebec provincial government have strategically invested hundreds of millions of dollars to build and sustain this ecosystem. The **Pan-Canadian Artificial Intelligence Strategy** was the first national AI strategy in the world, and it designated Montreal (via Mila) as one of its three primary centers of excellence. This public funding has been crucial for attracting and retaining top academic talent.\n\n### What Makes Montreal&amp;#x27;s AI Hub Unique?\n\n*   **Focus on Deep Learning:** While other cities have broad AI industries, Montreal&amp;#x27;s identity is deeply rooted in fundamental deep learning research.\n*   **Collaborative and Ethical Focus:** Led by Yoshua Bengio, there is a strong emphasis on developing AI for the common good. The **Montreal Declaration for a Responsible Development of Artificial Intelligence** is a landmark example of the community&amp;#x27;s commitment to ethics.\n*   **Affordable Quality of Life:** Compared to other major tech hubs like the San Francisco Bay Area, Montreal offers a much lower cost of living and a high quality of life, making it attractive for talent.\n*   **Cultural and Linguistic Diversity:** Its bilingual, multicultural, and European-influenced character gives it a unique and creative atmosphere.\n\n### Conclusion\n\nMontreal isn&amp;#x27;t just a city with a few AI companies; it is a **fully integrated ecosystem** where academia, industry, and government work in synergy. Its reputation as a foundational research center for deep learning gives it a unique and durable advantage, making it a **thriving, top-tier global hub for the AI industry.**\nINFO     serverless_models.multimodal_models.test_gemini_2_5_pro:test_gemini_2_5_pro.py:37 \u2705 Gemini 2.5 Pro test completed successfully\n\n&#34;}], &#34;tests/serverless_models/multimodal_models/test_gpt_4o_mini.py::test_gpt_4o_mini_simple&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/serverless_models/multimodal_models/test_gpt_4o_mini.py::test_gpt_4o_mini_simple&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/serverless_models/multimodal_models/test_gpt_4o_mini.py::test_gpt_4o_mini_simple&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\nINFO:serverless_models.multimodal_models.test_gpt_4o_mini:\ud83d\ude80 Starting GPT-4o Mini test with simple prompt\nINFO:api_clients.multimodal_models:Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO:serverless_models.multimodal_models.test_gpt_4o_mini:\u2705 MultimodalModelsAPI instance created successfully\nINFO:api_clients.multimodal_models:Calling gpt-4o-mini with text prompt\nINFO:serverless_models.multimodal_models.test_gpt_4o_mini:\ud83d\udcdd GPT-4o Mini response: Hello! How can I assist you today?\nINFO:serverless_models.multimodal_models.test_gpt_4o_mini:\u2705 GPT-4o Mini test completed successfully\n\n------------------------------ Captured log call -------------------------------\nINFO     serverless_models.multimodal_models.test_gpt_4o_mini:test_gpt_4o_mini.py:9 \ud83d\ude80 Starting GPT-4o Mini test with simple prompt\nINFO     api_clients.multimodal_models:multimodal_models.py:20 Using chat_completions_url: https://dev-llm-proxy.nebulablock.com/v1/chat/completions\nINFO     serverless_models.multimodal_models.test_gpt_4o_mini:test_gpt_4o_mini.py:13 \u2705 MultimodalModelsAPI instance created successfully\nINFO     api_clients.multimodal_models:multimodal_models.py:124 Calling gpt-4o-mini with text prompt\nINFO     serverless_models.multimodal_models.test_gpt_4o_mini:test_gpt_4o_mini.py:32 \ud83d\udcdd GPT-4o Mini response: Hello! How can I assist you today?\nINFO     serverless_models.multimodal_models.test_gpt_4o_mini:test_gpt_4o_mini.py:37 \u2705 GPT-4o Mini test completed successfully\n\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>